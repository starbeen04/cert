"""ì‹¤ì œ Claude APIë¥¼ í™œìš©í•œ AI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""

import asyncio
import json
import re
from typing import Dict, List, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from app.database import get_db
from services.claude_service import claude_service
from services.ocr_service import OCRService
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class RealAIProcessor:
    def __init__(self):
        self.ocr_service = OCRService()
    
    async def process_pdf_with_claude(self, upload_id: int, file_path: str, file_type: str, db: Session) -> Dict[str, Any]:
        """ì‹¤ì œ Claude APIë¥¼ ì‚¬ìš©í•œ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        try:
            print(f"ğŸš€ Starting REAL AI processing for upload {upload_id}")
            await self._log_progress(upload_id, "ğŸš€ ì‹¤ì œ Claude AI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘", db)
            
            # ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            db.execute(
                text("UPDATE pdf_uploads SET processing_status = 'processing' WHERE id = :id"),
                {"id": upload_id}
            )
            db.commit()
            
            # ë‹¨ê³„ë³„ AI ì²˜ë¦¬ ì‹œì‘
            total_cost = 0.0
            processed_questions = []
            processed_materials = []
            
            # 1ë‹¨ê³„: OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
            await self._create_ai_task(upload_id, "ocr_extraction", "processing", db)
            
            print("ğŸ“„ Step 1: OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            await self._log_progress(upload_id, "ğŸ“„ 1ë‹¨ê³„: OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...", db)
            ocr_result = self.ocr_service.process_pdf(file_path, file_type)
            
            if not ocr_result or not ocr_result.get("success"):
                await self._update_ai_task(upload_id, "ocr_extraction", "failed", {"error": "OCR ì‹¤íŒ¨"}, db)
                return {"error": "OCR processing failed"}
            
            extracted_text = ocr_result.get("extracted_text", "")
            print(f"ğŸ“ OCR ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text)} characters")
            
            if not extracted_text or len(extracted_text.strip()) < 100:
                error_msg = f"OCR ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(extracted_text)} ë¬¸ì). ìµœì†Œ 100ì ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤."
                await self._update_ai_task(upload_id, "ocr_extraction", "failed", {"error": error_msg}, db)
                return {"error": error_msg}
            
            await self._update_ai_task(upload_id, "ocr_extraction", "completed", {"text_length": len(extracted_text)}, db)
            
            # 2ë‹¨ê³„: Claude AIë¡œ ë¬¸ì„œ ë¶„ì„ ë° ë¶„ë¥˜
            await self._create_ai_task(upload_id, "document_analysis", "processing", db)
            
            print("ğŸ¤– Step 2: Claude AI ë¬¸ì„œ ë¶„ì„ ì¤‘...")
            await self._log_progress(upload_id, "ğŸ¤– 2ë‹¨ê³„: Claude AIë¡œ ë¬¸ì„œ ë¶„ì„ ì¤‘...", db)
            analysis_result = await self._analyze_document_with_claude(extracted_text, db)
            
            if analysis_result.get("success"):
                await self._update_ai_task(upload_id, "document_analysis", "completed", analysis_result, db)
                total_cost += analysis_result.get("cost", 0)
                print(f"âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ - ë¹„ìš©: ${analysis_result.get('cost', 0):.4f}")
            else:
                await self._update_ai_task(upload_id, "document_analysis", "failed", analysis_result, db)
                return {"error": "Document analysis failed"}
            
            # 3ë‹¨ê³„: íŒŒì¼ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
            if file_type in ["questions", "both"]:
                # ë¬¸ì œ ì¶”ì¶œ
                await self._create_ai_task(upload_id, "question_extraction", "processing", db)
                print("â“ Step 3: Claude AI ë¬¸ì œ ì¶”ì¶œ ì¤‘...")
                
                questions_result = await self._extract_questions_with_claude(extracted_text, analysis_result.get("document_type", ""), db)
                
                if questions_result.get("success"):
                    questions = questions_result.get("questions", [])
                    processed_questions = await self._save_questions_to_db(questions, upload_id, db)
                    await self._update_ai_task(upload_id, "question_extraction", "completed", {"count": len(questions)}, db)
                    total_cost += questions_result.get("cost", 0)
                    print(f"âœ… ë¬¸ì œ ì¶”ì¶œ ì™„ë£Œ - {len(questions)}ê°œ ë¬¸ì œ, ë¹„ìš©: ${questions_result.get('cost', 0):.4f}")
                else:
                    await self._update_ai_task(upload_id, "question_extraction", "failed", questions_result, db)
            
            if file_type in ["study_material", "both"]:
                # í•™ìŠµìë£Œ ìƒì„±
                await self._create_ai_task(upload_id, "material_generation", "processing", db)
                print("ğŸ“š Step 4: Claude AI í•™ìŠµìë£Œ ìƒì„± ì¤‘...")
                
                materials_result = await self._generate_materials_with_claude(extracted_text, analysis_result.get("key_topics", []), db)
                
                if materials_result.get("success"):
                    materials = materials_result.get("materials", [])
                    processed_materials = await self._save_materials_to_db(materials, upload_id, db)
                    await self._update_ai_task(upload_id, "material_generation", "completed", {"count": len(materials)}, db)
                    total_cost += materials_result.get("cost", 0)
                    print(f"âœ… í•™ìŠµìë£Œ ìƒì„± ì™„ë£Œ - {len(materials)}ê°œ ìë£Œ, ë¹„ìš©: ${materials_result.get('cost', 0):.4f}")
                else:
                    await self._update_ai_task(upload_id, "material_generation", "failed", materials_result, db)
            
            # 4ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦
            await self._create_ai_task(upload_id, "quality_verification", "processing", db)
            print("ğŸ” Step 5: Claude AI í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            
            quality_result = await self._verify_quality_with_claude(processed_questions, processed_materials, db)
            await self._update_ai_task(upload_id, "quality_verification", "completed", quality_result, db)
            total_cost += quality_result.get("cost", 0)
            
            # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
            db.execute(
                text("UPDATE pdf_uploads SET processing_status = 'completed', processed_date = CURRENT_TIMESTAMP WHERE id = :id"),
                {"id": upload_id}
            )
            db.commit()
            
            # API ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
            await self._update_api_usage(total_cost, db)
            
            result = {
                "success": True,
                "upload_id": upload_id,
                "questions_count": len(processed_questions),
                "materials_count": len(processed_materials),
                "total_cost": total_cost,
                "quality_score": quality_result.get("quality_score", 0)
            }
            
            print(f"ğŸ‰ AI ì²˜ë¦¬ ì™„ë£Œ! ë¬¸ì œ: {len(processed_questions)}ê°œ, ìë£Œ: {len(processed_materials)}ê°œ, ì´ ë¹„ìš©: ${total_cost:.4f}")
            return result
            
        except Exception as e:
            logger.error(f"Error in AI processing: {e}")
            db.execute(
                text("UPDATE pdf_uploads SET processing_status = 'failed' WHERE id = :id"),
                {"id": upload_id}
            )
            db.commit()
            return {"error": str(e)}
    
    async def _analyze_document_with_claude(self, text: str, db: Session) -> Dict[str, Any]:
        """Claude APIë¡œ ë¬¸ì„œ ë¶„ì„"""
        try:
            # ë¬¸ì„œ ë¶„ì„ ì—ì´ì „íŠ¸ ì¡°íšŒ (ì§ì ‘ sqlite3 ì‚¬ìš©)
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM ai_agents WHERE agent_type = 'document_analysis' AND is_active = 1 LIMIT 1")
            agent_row = cursor.fetchone()
            conn.close()
            
            if not agent_row:
                print("âŒ Document analysis agent not found!")
                return {"error": "Document analysis agent not found"}
            
            # Convert to dict for easier access
            agent = {
                "id": agent_row[0],
                "name": agent_row[1],
                "description": agent_row[2],
                "agent_type": agent_row[3],
                "model_name": agent_row[4],
                "provider": agent_row[5],
                "is_active": agent_row[6],
                "max_tokens": agent_row[7],
                "temperature": agent_row[8],
                "system_prompt": agent_row[9]
            }
            
            # ë””ë²„ê¹…: agent ì •ë³´ ì¶œë ¥
            print(f"ğŸ” Agent found: {agent['name']} (ID: {agent['id']})")
            print(f"ğŸ” Model: {agent['model_name']}")
            print(f"ğŸ” System prompt length: {len(agent['system_prompt']) if agent['system_prompt'] else 0}")
            
            prompt = f"""ë‹¤ìŒ PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

{text[:4000]}...

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "document_type": "ë¬¸ì œì§‘ ë˜ëŠ” êµì¬",
    "subject_area": "ì£¼ì œ ë¶„ì•¼ (ì˜ˆ: ì •ë³´ì²˜ë¦¬, ë°ì´í„°ë² ì´ìŠ¤, í”„ë¡œê·¸ë˜ë°)",
    "difficulty_level": "ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰",
    "has_questions": true/false,
    "has_theory": true/false,
    "estimated_questions": ì¶”ì •_ë¬¸ì œìˆ˜,
    "key_topics": ["ì£¼ìš” í† í”½1", "ì£¼ìš” í† í”½2", "ì£¼ìš” í† í”½3"],
    "content_summary": "ë‚´ìš© ìš”ì•½"
}}"""
            
            # Agent ë”•ì…”ë„ˆë¦¬ ìƒì„±
            agent_dict = {
                "model_name": agent['model_name'],
                "system_prompt": agent['system_prompt'] or '',
                "max_tokens": agent['max_tokens'] or 4000,
                "temperature": agent['temperature'] or 0.7
            }
            
            print(f"ğŸ” Agent dict created: {agent_dict}")
            
            # Claude API í˜¸ì¶œ
            response = await claude_service.call_claude_api_direct(prompt, agent_dict, db)
            
            if response.get("success"):
                content = response["content"]
                # JSON ì¶”ì¶œ
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    analysis = json.loads(json_match.group())
                    return {
                        "success": True,
                        "analysis": analysis,
                        "document_type": analysis.get("document_type", "unknown"),
                        "key_topics": analysis.get("key_topics", []),
                        "usage": response.get("usage", {}),
                        "cost": self._calculate_cost(response.get("usage", {}))
                    }
            
            return {"error": "Failed to analyze document"}
            
        except Exception as e:
            logger.error(f"Error in document analysis: {e}")
            return {"error": str(e)}
    
    async def _extract_questions_with_claude(self, text: str, document_type: str, db: Session) -> Dict[str, Any]:
        """Claude APIë¡œ ë¬¸ì œ ì¶”ì¶œ - ë‹¤ì¤‘ ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬"""
        try:
            # ë¬¸ì œ ì¶”ì¶œ ì—ì´ì „íŠ¸ ì¡°íšŒ (ì§ì ‘ sqlite3 ì‚¬ìš©)
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM ai_agents WHERE agent_type = 'question_extraction' AND is_active = 1 LIMIT 1")
            agent_row = cursor.fetchone()
            conn.close()
            
            if not agent_row:
                return {"error": "Question extraction agent not found"}
            
            # Convert to dict
            agent = {
                "model_name": agent_row[4],
                "system_prompt": agent_row[9] or '',
                "max_tokens": agent_row[7] or 8000,
                "temperature": 0.3  # ì •í™•ë„ë¥¼ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
            }
            
            print(f"ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} characters")
            
            # í…ìŠ¤íŠ¸ë¥¼ 4000ì ì²­í¬ë¡œ ë¶„í•  (overlap 500ì)
            chunk_size = 4000
            overlap = 500
            chunks = []
            
            for i in range(0, len(text), chunk_size - overlap):
                chunk = text[i:i + chunk_size]
                if chunk.strip():
                    chunks.append(chunk)
            
            print(f"ğŸ”„ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
            
            # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
            all_questions = []
            total_cost = 0
            
            for chunk_idx, chunk in enumerate(chunks):
                print(f"ğŸ“‹ ì²­í¬ {chunk_idx + 1}/{len(chunks)} ì²˜ë¦¬ ì¤‘...")
                
                enhanced_prompt = f"""ë‹¤ìŒì€ ìê²©ì¦ ì‹œí—˜ ë¬¸ì œì§‘ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ê°ê´€ì‹ ë¬¸ì œë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

=== ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ===
{chunk}

=== ì¶”ì¶œ ê·œì¹™ ===
1. ë¬¸ì œ ë²ˆí˜¸ê°€ ìˆëŠ” ëª¨ë“  ê°ê´€ì‹ ë¬¸ì œë¥¼ ì°¾ìœ¼ì„¸ìš”
2. ê° ë¬¸ì œì˜ ì„ íƒì§€(â‘ â‘¡â‘¢â‘£ ë˜ëŠ” 1)2)3)4))ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”  
3. ì •ë‹µì´ ëª…ì‹œë˜ì–´ ìˆë‹¤ë©´ í¬í•¨í•˜ì„¸ìš”
4. í•´ì„¤ì´ ìˆë‹¤ë©´ í¬í•¨í•˜ì„¸ìš”

=== ì¶œë ¥ í˜•ì‹ ===
ë°˜ë“œì‹œ ë‹¤ìŒ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

[
    {{
        "question_number": ë¬¸ì œë²ˆí˜¸,
        "question_text": "ì™„ì „í•œ ë¬¸ì œ ë‚´ìš©",
        "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
        "correct_answer": "ì •ë‹µ",
        "topic_category": "ì¶”ì • ì£¼ì œ ë¶„ì•¼",
        "difficulty_level": "ì´ˆê¸‰",
        "explanation": "í•´ì„¤ ë‚´ìš© ë˜ëŠ” null"
    }}
]

ì¤‘ìš”: 
- ë¬¸ì œê°€ ì—†ë‹¤ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”
- JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
- í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ë˜ëŠ” ëª¨ë“  ë¬¸ì œë¥¼ ëˆ„ë½ ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”"""

                try:
                    response = await claude_service.call_claude_api_direct(enhanced_prompt, agent, db, max_tokens=8000)
                    
                    if response.get("success"):
                        content = response["content"]
                        # JSON ë°°ì—´ ì¶”ì¶œ (ë” ê°•ë ¥í•œ íŒŒì‹±)
                        json_match = re.search(r'\[\s*\{.*?\}\s*\]', content, re.DOTALL)
                        if json_match:
                            try:
                                chunk_questions = json.loads(json_match.group())
                                if isinstance(chunk_questions, list):
                                    for q in chunk_questions:
                                        if isinstance(q, dict) and q.get("question_text"):
                                            all_questions.append(q)
                                    print(f"âœ… ì²­í¬ {chunk_idx + 1}: {len(chunk_questions)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
                                else:
                                    print(f"âš ï¸ ì²­í¬ {chunk_idx + 1}: ì˜ëª»ëœ JSON í˜•ì‹")
                            except json.JSONDecodeError as e:
                                print(f"âŒ ì²­í¬ {chunk_idx + 1}: JSON íŒŒì‹± ì˜¤ë¥˜ - {e}")
                        else:
                            print(f"âš ï¸ ì²­í¬ {chunk_idx + 1}: JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        
                        total_cost += self._calculate_cost(response.get("usage", {}))
                    else:
                        print(f"âŒ ì²­í¬ {chunk_idx + 1}: API í˜¸ì¶œ ì‹¤íŒ¨")
                        
                except Exception as e:
                    print(f"âŒ ì²­í¬ {chunk_idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
                
                # API í˜¸ì¶œ ê°„ê²© (rate limit ë°©ì§€)
                await asyncio.sleep(1)
            
            print(f"ğŸ‰ ì „ì²´ ì¶”ì¶œ ì™„ë£Œ: {len(all_questions)}ê°œ ë¬¸ì œ, ì´ ë¹„ìš©: ${total_cost:.4f}")
            
            return {
                "success": True,
                "questions": all_questions,
                "count": len(all_questions),
                "chunks_processed": len(chunks),
                "total_cost": total_cost
            }
            
        except Exception as e:
            logger.error(f"Error in question extraction: {e}")
            return {"error": str(e)}
    
    async def _generate_materials_with_claude(self, text: str, topics: List[str], db: Session) -> Dict[str, Any]:
        """Claude APIë¡œ í•™ìŠµìë£Œ ìƒì„±"""
        try:
            # í•™ìŠµìë£Œ ìƒì„± ì—ì´ì „íŠ¸ ì¡°íšŒ (ì§ì ‘ sqlite3 ì‚¬ìš©)
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM ai_agents WHERE agent_type = 'study_material_generation' AND is_active = 1 LIMIT 1")
            agent_row = cursor.fetchone()
            conn.close()
            
            if not agent_row:
                return {"error": "Study material generation agent not found"}
            
            agent = {
                "model_name": agent_row[4],
                "system_prompt": agent_row[9] or '',
                "max_tokens": agent_row[7] or 6000,
                "temperature": agent_row[8] or 0.7
            }
            
            topics_str = ", ".join(topics) if topics else "ì¼ë°˜"
            
            prompt = f"""ë‹¤ìŒ êµì¬ í…ìŠ¤íŠ¸ì™€ ì£¼ìš” í† í”½ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµìë£Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text[:4000]}...
ì£¼ìš” í† í”½: {topics_str}

ë‹¤ìŒ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ í•™ìŠµìë£Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
[
    {{
        "title": "í•™ìŠµìë£Œ ì œëª©",
        "content": "ìƒì„¸í•œ í•™ìŠµ ë‚´ìš© (ìµœì†Œ 200ì ì´ìƒ)",
        "content_type": "ê°œë…ì •ë¦¬/ìš”ì•½/ì˜ˆì œ",
        "difficulty_level": "ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰",
        "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
    }}
]

ì²´ê³„ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•™ìŠµìë£Œë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ìƒì„±í•´ì£¼ì„¸ìš”."""
            
            agent_dict = agent
            response = await claude_service.call_claude_api_direct(prompt, agent_dict, db, max_tokens=6000)
            
            if response.get("success"):
                content = response["content"]
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    materials = json.loads(json_match.group())
                    return {
                        "success": True,
                        "materials": materials,
                        "count": len(materials),
                        "usage": response.get("usage", {}),
                        "cost": self._calculate_cost(response.get("usage", {}))
                    }
            
            return {"error": "Failed to generate materials"}
            
        except Exception as e:
            logger.error(f"Error in material generation: {e}")
            return {"error": str(e)}
    
    async def _verify_quality_with_claude(self, questions: List, materials: List, db: Session) -> Dict[str, Any]:
        """Claude APIë¡œ í’ˆì§ˆ ê²€ì¦"""
        try:
            # í’ˆì§ˆ ê²€ì¦ ì—ì´ì „íŠ¸ ì¡°íšŒ (ì§ì ‘ sqlite3 ì‚¬ìš©)
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM ai_agents WHERE agent_type = 'quality_verification' AND is_active = 1 LIMIT 1")
            agent_row = cursor.fetchone()
            conn.close()
            
            if not agent_row:
                return {"success": True, "quality_score": 80, "feedback": "í’ˆì§ˆ ê²€ì¦ ì—ì´ì „íŠ¸ ì—†ìŒ", "cost": 0}
            
            agent = {
                "model_name": agent_row[4],
                "system_prompt": agent_row[9] or '',
                "max_tokens": agent_row[7] or 1000,
                "temperature": agent_row[8] or 0.7
            }
            
            prompt = f"""ë‹¤ìŒ AI ì²˜ë¦¬ ê²°ê³¼ì˜ í’ˆì§ˆì„ ê²€ì¦í•´ì£¼ì„¸ìš”:

ì¶”ì¶œëœ ë¬¸ì œ ìˆ˜: {len(questions)}
ìƒì„±ëœ í•™ìŠµìë£Œ ìˆ˜: {len(materials)}

JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "quality_score": 0-100ì ,
    "accuracy_score": 0-100ì ,
    "completeness_score": 0-100ì ,
    "feedback": "ì¢…í•© í‰ê°€ ë° ê°œì„ ì‚¬í•­",
    "recommendations": ["ì¶”ì²œì‚¬í•­1", "ì¶”ì²œì‚¬í•­2"]
}}"""
            
            agent_dict = agent
            response = await claude_service.call_claude_api_direct(prompt, agent_dict, db, max_tokens=1000)
            
            if response.get("success"):
                content = response["content"]
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    quality_result = json.loads(json_match.group())
                    quality_result["success"] = True
                    quality_result["cost"] = self._calculate_cost(response.get("usage", {}))
                    return quality_result
            
            return {"success": True, "quality_score": 75, "feedback": "í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ", "cost": 0}
            
        except Exception as e:
            logger.error(f"Error in quality verification: {e}")
            return {"success": True, "quality_score": 70, "feedback": f"ê²€ì¦ ì˜¤ë¥˜: {str(e)}", "cost": 0}
    
    async def _save_questions_to_db(self, questions: List[Dict], upload_id: int, db: Session) -> List[Dict]:
        """ë¬¸ì œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        saved_questions = []
        
        for i, question in enumerate(questions):
            try:
                result = db.execute(
                    text("""
                        INSERT INTO extracted_questions 
                        (pdf_upload_id, question_number, question_text, options, correct_answer, topic_category, difficulty_level, explanation)
                        VALUES (:pdf_id, :q_num, :q_text, :options, :answer, :category, :difficulty, :explanation)
                    """),
                    {
                        "pdf_id": upload_id,
                        "q_num": question.get("question_number", i + 1),
                        "q_text": question.get("question_text", ""),
                        "options": json.dumps(question.get("options", []), ensure_ascii=False),
                        "answer": question.get("correct_answer", ""),
                        "category": question.get("topic_category", "ì¼ë°˜"),
                        "difficulty": question.get("difficulty_level", "ì¤‘ê¸‰"),
                        "explanation": question.get("explanation", "")
                    }
                )
                db.flush()
                
                saved_questions.append({
                    "id": result.lastrowid,
                    "question_text": question.get("question_text", ""),
                    "topic_category": question.get("topic_category", "ì¼ë°˜")
                })
                
            except Exception as e:
                logger.error(f"Error saving question {i}: {e}")
                continue
        
        db.commit()
        return saved_questions
    
    async def _save_materials_to_db(self, materials: List[Dict], upload_id: int, db: Session) -> List[Dict]:
        """í•™ìŠµìë£Œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        saved_materials = []
        
        for i, material in enumerate(materials):
            try:
                result = db.execute(
                    text("""
                        INSERT INTO study_materials 
                        (pdf_upload_id, title, content, content_type, difficulty_level, keywords, chapter_number, section_number)
                        VALUES (:pdf_id, :title, :content, :content_type, :difficulty, :keywords, :chapter, :section)
                    """),
                    {
                        "pdf_id": upload_id,
                        "title": material.get("title", f"í•™ìŠµìë£Œ {i+1}"),
                        "content": material.get("content", ""),
                        "content_type": material.get("content_type", "ê°œë…ì •ë¦¬"),
                        "difficulty": material.get("difficulty_level", "ì¤‘ê¸‰"),
                        "keywords": json.dumps(material.get("keywords", []), ensure_ascii=False),
                        "chapter": 1,
                        "section": i + 1
                    }
                )
                db.flush()
                
                saved_materials.append({
                    "id": result.lastrowid,
                    "title": material.get("title", f"í•™ìŠµìë£Œ {i+1}"),
                    "content_type": material.get("content_type", "ê°œë…ì •ë¦¬")
                })
                
            except Exception as e:
                logger.error(f"Error saving material {i}: {e}")
                continue
        
        db.commit()
        return saved_materials
    
    def _calculate_cost(self, usage: Dict[str, Any]) -> float:
        """í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚°"""
        if not usage:
            return 0.0
        
        input_tokens = usage.get("input_tokens", 0)
        output_tokens = usage.get("output_tokens", 0)
        
        # Claude 3.5 Sonnet ê°€ê²© (2024 ê¸°ì¤€)
        input_cost_per_token = 0.000003  # $0.003 per 1K tokens
        output_cost_per_token = 0.000015  # $0.015 per 1K tokens
        
        return (input_tokens * input_cost_per_token) + (output_tokens * output_cost_per_token)
    
    async def _create_ai_task(self, upload_id: int, agent_type: str, status: str, db: Session):
        """AI ì‘ì—… ìƒì„± (ì§ì ‘ sqlite3 ì‚¬ìš©)"""
        try:
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO ai_tasks (file_upload_id, task_type, status, started_at, created_at)
                VALUES (?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """, (upload_id, agent_type, status))
            
            conn.commit()
            conn.close()
            logger.info(f"Created AI task: {agent_type} for upload {upload_id}")
        except Exception as e:
            logger.error(f"Error creating AI task: {e}")
    
    async def _update_ai_task(self, upload_id: int, agent_type: str, status: str, result_data: Dict, db: Session):
        """AI ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸ (ì§ì ‘ sqlite3 ì‚¬ìš©)"""
        try:
            import sqlite3
            conn = sqlite3.connect('database.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE ai_tasks 
                SET status = ?, 
                    output_data = ?,
                    completed_at = CURRENT_TIMESTAMP,
                    updated_at = CURRENT_TIMESTAMP
                WHERE file_upload_id = ? AND task_type = ?
            """, (status, json.dumps(result_data, ensure_ascii=False), upload_id, agent_type))
            
            conn.commit()
            conn.close()
            logger.info(f"Updated AI task: {agent_type} for upload {upload_id} - {status}")
        except Exception as e:
            logger.error(f"Error updating AI task: {e}")
    
    async def _log_progress(self, upload_id: int, message: str, db: Session):
        """ì§„í–‰ ìƒí™© ë¡œê·¸"""
        try:
            # ê°„ë‹¨í•œ ì§„í–‰ ë¡œê·¸ (ë‚˜ì¤‘ì— WebSocketìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
            print(f"ğŸ“ Upload {upload_id}: {message}")
        except Exception as e:
            logger.error(f"Error logging progress: {e}")
    
    async def _update_api_usage(self, cost: float, db: Session):
        """API ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
        try:
            # í™œì„±í™”ëœ API í‚¤ ì¡°íšŒ
            api_key = db.execute(
                text("SELECT * FROM api_keys WHERE is_active = 1 AND provider = 'anthropic' LIMIT 1")
            ).fetchone()
            
            if api_key:
                # ì¼ì¼ ë° ì›”ê°„ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
                db.execute(
                    text("""
                        UPDATE api_keys 
                        SET current_daily_usage = current_daily_usage + :cost,
                            current_monthly_usage = current_monthly_usage + :cost,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = :key_id
                    """),
                    {"cost": cost, "key_id": api_key.id}
                )
                
                # ì‚¬ìš© ë¡œê·¸ ìƒì„±
                db.execute(
                    text("""
                        INSERT INTO ai_usage_logs (api_key_id, agent_type, tokens_used, cost_usd, created_at)
                        VALUES (:key_id, :agent_type, :tokens, :cost, CURRENT_TIMESTAMP)
                    """),
                    {
                        "key_id": api_key.id,
                        "agent_type": "document_processing",
                        "tokens": 1000,  # ì‹¤ì œ í† í° ìˆ˜ëŠ” usageì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
                        "cost": cost
                    }
                )
                db.commit()
                
        except Exception as e:
            logger.error(f"Error updating API usage: {e}")
            db.rollback()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
real_ai_processor = RealAIProcessor()