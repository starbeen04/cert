#!/usr/bin/env python3
"""
ğŸš€ í†µí•© PDF ì²˜ë¦¬ ì‹œìŠ¤í…œ: í˜ì´ì§€ ê²½ê³„ë¥¼ ë¬´ì‹œí•œ ì „ì²´ì  ì ‘ê·¼ ë°©ì‹
ê¸°ì¡´ í˜ì´ì§€ë³„ ì²˜ë¦¬ì˜ ë¬¸ì œì ë“¤ì„ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜
"""

import re
import json
import base64
from PIL import Image
import io
import os
import asyncio
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import fitz  # PyMuPDF
import openai
from datetime import datetime
import numpy as np

class UnifiedPDFProcessor:
    """í†µí•© PDF ì²˜ë¦¬ ì‹œìŠ¤í…œ - í˜ì´ì§€ ê²½ê³„ ë¬´ì‹œí•˜ê³  ì „ì²´ì ìœ¼ë¡œ ì²˜ë¦¬"""
    
    def __init__(self, openai_client: openai.AsyncOpenAI):
        self.openai_client = openai_client
        
        # PDF ì „ì²´ ê·œì¹™
        self.PDF_RULES = {
            "total_questions": 60,
            "questions_per_page": 15,  # í‰ê· ì ìœ¼ë¡œ
            "choice_markers": ["â‘ ", "â‘¡", "â‘¢", "â‘£"],
            "subjects": {
                "1-20": "ì •ë³´ì‹œìŠ¤í…œ ê¸°ë°˜ ê¸°ìˆ ", 
                "21-40": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ í™œìš©",
                "41-60": "ë°ì´í„°ë² ì´ìŠ¤ í™œìš©"
            }
        }
    
    async def process_pdf_unified(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """í†µí•© ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        
        print("ğŸš€ í†µí•© PDF ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)
        
        try:
            # === 1ë‹¨ê³„: ì „ì²´ PDF ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• ===
            print("ğŸ“‹ 1ë‹¨ê³„: ì „ì²´ PDF ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•")
            full_context = await self._build_full_pdf_context(pdf_path, upload_id)
            
            # === 2ë‹¨ê³„: í¬ë¡œìŠ¤ í˜ì´ì§€ ì¸ì‹ ì²˜ë¦¬ ===
            print("ğŸ”— 2ë‹¨ê³„: í¬ë¡œìŠ¤ í˜ì´ì§€ ì—°ê²° ì²˜ë¦¬")
            connected_content = await self._process_cross_page_connections(full_context)
            
            # === 3ë‹¨ê³„: í†µí•© ë¬¸ì œ ì¶”ì¶œ ===
            print("ğŸ“ 3ë‹¨ê³„: í†µí•© ë¬¸ì œ ì¶”ì¶œ")
            unified_questions = await self._extract_questions_unified(connected_content)
            
            # === 4ë‹¨ê³„: íŠ¹ìˆ˜ ìš”ì†Œ í†µí•© ì²˜ë¦¬ ===
            print("ğŸ¨ 4ë‹¨ê³„: íŠ¹ìˆ˜ ìš”ì†Œ í†µí•© ì²˜ë¦¬")
            enhanced_questions = await self._process_special_elements_unified(unified_questions, full_context)
            
            # === 5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ì •ë¦¬ ===
            print("âœ… 5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ì •ë¦¬")
            final_questions = self._finalize_and_validate(enhanced_questions)
            
            print(f"âœ… í†µí•© ì²˜ë¦¬ ì™„ë£Œ: {len(final_questions)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
            
            return {
                "success": True,
                "questions": final_questions,
                "total_questions": len(final_questions),
                "processing_method": "unified_processing",
                "context_data": full_context
            }
            
        except Exception as e:
            print(f"âŒ í†µí•© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}
    
    async def _build_full_pdf_context(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """1ë‹¨ê³„: ì „ì²´ PDF ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• - í˜ì´ì§€ ê²½ê³„ ì •ë³´ í¬í•¨"""
        
        assets_dir = Path(f"assets/upload_{upload_id}")
        assets_dir.mkdir(parents=True, exist_ok=True)
        
        doc = fitz.open(pdf_path)
        
        # ì „ì²´ PDFë¥¼ í•˜ë‚˜ì˜ í° ì´ë¯¸ì§€ë¡œ ì—°ê²° (ì„¸ë¡œ ë°©í–¥)
        combined_image = self._create_combined_image(doc, assets_dir)
        
        # í˜ì´ì§€ë³„ ì •ë³´ë„ í•¨ê»˜ ì €ì¥ (ìœ„ì¹˜ ì°¸ì¡°ìš©)
        page_boundaries = []
        current_height = 0
        
        pages_info = []
        for page_num in range(len(doc)):
            page = doc[page_num]
            
            # í˜ì´ì§€ ì´ë¯¸ì§€ ìƒì„±
            mat = fitz.Matrix(3.0, 3.0)  # 300dpi
            pix = page.get_pixmap(matrix=mat)
            img_path = assets_dir / f"page_{page_num + 1}.png"
            pix.save(str(img_path))
            
            # í˜ì´ì§€ ê²½ê³„ ì •ë³´
            page_height = pix.height
            page_boundaries.append({
                "page_number": page_num + 1,
                "start_y": current_height,
                "end_y": current_height + page_height,
                "height": page_height,
                "image_path": str(img_path)
            })
            current_height += page_height
            
            # í…ìŠ¤íŠ¸ì™€ ì¢Œí‘œ ì •ë³´
            text_dict = page.get_text("dict")
            raw_text = page.get_text()
            
            pages_info.append({
                "page_number": page_num + 1,
                "raw_text": raw_text,
                "text_dict": text_dict,
                "image_path": str(img_path),
                "boundary": page_boundaries[-1]
            })
        
        doc.close()
        
        return {
            "combined_image_path": str(assets_dir / "combined_full.png"),
            "page_boundaries": page_boundaries,
            "pages_info": pages_info,
            "total_height": current_height,
            "assets_dir": str(assets_dir)
        }
    
    def _create_combined_image(self, doc: fitz.Document, assets_dir: Path) -> str:
        """ëª¨ë“  í˜ì´ì§€ë¥¼ ì„¸ë¡œë¡œ ì—°ê²°í•œ í†µí•© ì´ë¯¸ì§€ ìƒì„±"""
        
        page_images = []
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            mat = fitz.Matrix(3.0, 3.0)  # 300dpi
            pix = page.get_pixmap(matrix=mat)
            
            # PIL Imageë¡œ ë³€í™˜
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            page_images.append(img)
        
        if not page_images:
            return ""
        
        # ëª¨ë“  ì´ë¯¸ì§€ì˜ ë„ˆë¹„ëŠ” ê°™ë‹¤ê³  ê°€ì •í•˜ê³ , ë†’ì´ë¥¼ í•©ì³ì„œ í•˜ë‚˜ì˜ ê¸´ ì´ë¯¸ì§€ ìƒì„±
        total_width = page_images[0].width
        total_height = sum(img.height for img in page_images)
        
        combined_image = Image.new('RGB', (total_width, total_height), 'white')
        
        current_y = 0
        for img in page_images:
            combined_image.paste(img, (0, current_y))
            current_y += img.height
        
        # ì €ì¥
        combined_path = assets_dir / "combined_full.png"
        combined_image.save(combined_path)
        
        return str(combined_path)
    
    async def _process_cross_page_connections(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """2ë‹¨ê³„: í¬ë¡œìŠ¤ í˜ì´ì§€ ì—°ê²° ë¶„ì„"""
        
        print("   ğŸ”— í¬ë¡œìŠ¤ í˜ì´ì§€ ê²½ê³„ ë¶„ì„ ì¤‘...")
        
        # í˜ì´ì§€ ê²½ê³„ì—ì„œ ì˜ë¦° ìš”ì†Œë“¤ íƒì§€
        cross_page_elements = []
        
        for i in range(len(context["page_boundaries"]) - 1):
            current_page = context["page_boundaries"][i]
            next_page = context["page_boundaries"][i + 1]
            
            # ê²½ê³„ ë¶€ê·¼ì˜ í…ìŠ¤íŠ¸ ë¶„ì„
            boundary_analysis = self._analyze_page_boundary(
                context["pages_info"][i], 
                context["pages_info"][i + 1]
            )
            
            if boundary_analysis["has_cross_page_element"]:
                cross_page_elements.append({
                    "from_page": current_page["page_number"],
                    "to_page": next_page["page_number"],
                    "element_type": boundary_analysis["element_type"],
                    "partial_content": boundary_analysis["content"]
                })
        
        print(f"   ğŸ“Š í¬ë¡œìŠ¤ í˜ì´ì§€ ìš”ì†Œ {len(cross_page_elements)}ê°œ ë°œê²¬")
        
        context["cross_page_elements"] = cross_page_elements
        return context
    
    def _analyze_page_boundary(self, current_page: Dict, next_page: Dict) -> Dict[str, Any]:
        """í˜ì´ì§€ ê²½ê³„ ë¶„ì„ - ì˜ë¦° ìš”ì†Œ íƒì§€"""
        
        current_text = current_page["raw_text"]
        next_text = next_page["raw_text"]
        
        # í˜„ì¬ í˜ì´ì§€ ëë¶€ë¶„ (ë§ˆì§€ë§‰ 10ì¤„)
        current_lines = current_text.strip().split('\n')[-10:]
        # ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ë¶€ë¶„ (ì²˜ìŒ 10ì¤„)
        next_lines = next_text.strip().split('\n')[:10]
        
        # ì˜ë¦° ì„ íƒì§€ íŒ¨í„´ íƒì§€
        choice_patterns = [r'â‘ .*', r'â‘¡.*', r'â‘¢.*', r'â‘£.*']
        incomplete_choices = []
        
        for line in current_lines:
            for pattern in choice_patterns:
                if re.search(pattern, line) and (len(line) < 20 or line.endswith('...')):
                    incomplete_choices.append(line)
        
        # ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì—°ê²°ë˜ëŠ” ë¶€ë¶„ ì°¾ê¸°
        continuation_found = False
        for line in next_lines:
            for pattern in choice_patterns:
                if re.search(pattern, line):
                    continuation_found = True
                    break
        
        # í‘œ ê²½ê³„ ë¶„ì„
        table_boundary = self._detect_table_boundary(current_lines, next_lines)
        
        if incomplete_choices or table_boundary["has_table_split"]:
            return {
                "has_cross_page_element": True,
                "element_type": "table" if table_boundary["has_table_split"] else "choices",
                "content": {
                    "incomplete_choices": incomplete_choices,
                    "table_info": table_boundary,
                    "continuation_found": continuation_found
                }
            }
        
        return {"has_cross_page_element": False, "element_type": None, "content": None}
    
    def _detect_table_boundary(self, current_lines: List[str], next_lines: List[str]) -> Dict[str, Any]:
        """í‘œ ê²½ê³„ íƒì§€"""
        
        # í‘œ íŒ¨í„´ (í”„ë¡œì„¸ìŠ¤, ë„ì°©ì‹œê°„, ì‹¤í–‰ì‹œê°„ ë“±)
        table_keywords = ["í”„ë¡œì„¸ìŠ¤", "ë„ì°©ì‹œê°„", "ì‹¤í–‰ì‹œê°„", "P1", "P2", "P3", "|"]
        
        current_has_table = any(keyword in ' '.join(current_lines) for keyword in table_keywords)
        next_has_table = any(keyword in ' '.join(next_lines) for keyword in table_keywords)
        
        # í˜„ì¬ í˜ì´ì§€ì—ëŠ” í—¤ë”ê°€ ìˆê³  ë‹¤ìŒ í˜ì´ì§€ì—ëŠ” ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        header_pattern = r'í”„ë¡œì„¸ìŠ¤.*ë„ì°©ì‹œê°„.*ì‹¤í–‰ì‹œê°„'
        data_pattern = r'P[1-9].*\d+.*\d+'
        
        has_header_current = bool(re.search(header_pattern, ' '.join(current_lines)))
        has_data_next = bool(re.search(data_pattern, ' '.join(next_lines)))
        
        return {
            "has_table_split": (current_has_table and next_has_table) or (has_header_current and has_data_next),
            "header_in_current": has_header_current,
            "data_in_next": has_data_next,
            "keywords_found": [kw for kw in table_keywords if kw in ' '.join(current_lines + next_lines)]
        }
    
    async def _extract_questions_unified(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """3ë‹¨ê³„: í†µí•© ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ ë¬¸ì œ ì¶”ì¶œ"""
        
        print("   ğŸ“ í†µí•© ì´ë¯¸ì§€ë¡œ ì „ì²´ ë¬¸ì œ ì¶”ì¶œ ì¤‘...")
        
        # í†µí•© ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        with open(context["combined_image_path"], "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # í†µí•© ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ - OCR ì •í™•ë„ í–¥ìƒ í¬í•¨
        prompt = """ì´ PDF ì „ì²´ ì´ë¯¸ì§€ì—ì„œ 60ê°œì˜ ì‹œí—˜ ë¬¸ì œë¥¼ ëª¨ë‘ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.

**í•µì‹¬ ê°œì„ ì‚¬í•­:**
- í˜ì´ì§€ ê²½ê³„ë¥¼ ë„˜ë‚˜ë“œëŠ” ì„ íƒì§€/í‘œ/ì½”ë“œë¥¼ ì™„ì „íˆ ì¶”ì¶œí•˜ì„¸ìš”
- ì˜ë¦° ë‚´ìš©ì€ ì—°ê²°í•´ì„œ ì™„ì„±í•˜ì„¸ìš”
- í‘œì˜ ê²½ìš° í—¤ë”ì™€ ë°ì´í„°ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”
- ë¬¸ì œ ë²ˆí˜¸ 1ë²ˆë¶€í„° 60ë²ˆê¹Œì§€ ëª¨ë“  ë¬¸ì œë¥¼ ì°¾ì•„ì„œ ì¶”ì¶œí•˜ì„¸ìš”

**ë¬¸ì ì¸ì‹ ì •í™•ë„ í–¥ìƒ ê·œì¹™:**
- ìˆ«ì: 2/3, 0/O, 1/l/I, 5/S, 8/B, 6/9 ì •í™•íˆ êµ¬ë¶„
- ê¸°í˜¸: *, +, =, -, /, %, !=, <=, >= ì •í™•íˆ ì¸ì‹
- í•œê¸€: ë°›ì¹¨ ìœ ë¬´, ëª¨ìŒ êµ¬ë¶„ (ã…/ã…“, ã…—/ã…œ) ì •í™•íˆ ì¸ì‹
- ì˜ë¬¸: ëŒ€ì†Œë¬¸ì, ë³€ìˆ˜ëª…, í•¨ìˆ˜ëª… ì •í™•íˆ ë³µì‚¬
- ê´„í˜¸: (), {}, [], <> í˜•íƒœ ì •í™•íˆ êµ¬ë¶„
- ì„ íƒì§€: â‘ â‘¡â‘¢â‘£ ë§ˆì»¤ ì •í™•íˆ ì¸ì‹

**í‘œ/ì½”ë“œ/ì´ë¯¸ì§€ ì²˜ë¦¬:**
- í‘œ: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •í™•í•œ êµ¬ì¡° ìœ ì§€
- ì½”ë“œ: ë“¤ì—¬ì“°ê¸°ì™€ ë¬¸ë²• ì •í™•íˆ ë³´ì¡´
- ì„ íƒì§€: ì¤‘ë³µ ì—†ì´ ì™„ì „í•œ ë‚´ìš©ìœ¼ë¡œ ì¶”ì¶œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (ë°±í‹± ì—†ì´ ì§ì ‘):

{
  "questions": [
    {
      "question_number": 1,
      "question_text": "ë¬¸ì œ ë‚´ìš©",
      "choices": [
        {"marker": "â‘ ", "content": "ì„ íƒì§€ 1"},
        {"marker": "â‘¡", "content": "ì„ íƒì§€ 2"},
        {"marker": "â‘¢", "content": "ì„ íƒì§€ 3"},
        {"marker": "â‘£", "content": "ì„ íƒì§€ 4"}
      ],
      "passage": "ë³´ê¸° ë‚´ìš© (ìˆëŠ” ê²½ìš°)",
      "has_table": false,
      "has_image": false,
      "has_code": false,
      "y_position": 1200
    }
  ]
}"""
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "PDF ì‹œí—˜ ë¬¸ì œ í†µí•© ì¶”ì¶œ ì „ë¬¸ê°€. í˜ì´ì§€ ê²½ê³„ë¥¼ ë„˜ë‚˜ë“œëŠ” ë‚´ìš©ì„ ì™„ì „íˆ ì—°ê²°í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=16000,  # ë” í° ì‘ë‹µ í—ˆìš©
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            result = self._parse_questions_json(response_text)
            
            if result and "questions" in result:
                questions = result["questions"]
                print(f"   âœ… í†µí•© ì¶”ì¶œ ì™„ë£Œ: {len(questions)}ê°œ ë¬¸ì œ")
                return questions
            else:
                print("   âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
                return []
                
        except Exception as e:
            print(f"   âŒ í†µí•© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_questions_json(self, response_text: str) -> Optional[Dict]:
        """JSON ì‘ë‹µ íŒŒì‹±"""
        try:
            # ```json ... ``` ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = response_text
            
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    async def _process_special_elements_unified(self, questions: List[Dict], context: Dict[str, Any]) -> List[Dict]:
        """4ë‹¨ê³„: íŠ¹ìˆ˜ ìš”ì†Œ í†µí•© ì²˜ë¦¬"""
        
        print("   ğŸ¨ íŠ¹ìˆ˜ ìš”ì†Œ í†µí•© ì²˜ë¦¬ ì¤‘...")
        
        special_questions = []
        for question in questions:
            # í‘œê°€ ìˆëŠ” ë¬¸ì œ ì²˜ë¦¬
            if question.get('has_table'):
                enhanced_q = await self._enhance_table_question(question, context)
                special_questions.append(enhanced_q)
            # ì½”ë“œê°€ ìˆëŠ” ë¬¸ì œ ì²˜ë¦¬
            elif question.get('has_code'):
                enhanced_q = await self._enhance_code_question(question, context)
                special_questions.append(enhanced_q)
            # ì´ë¯¸ì§€ê°€ ìˆëŠ” ë¬¸ì œ ì²˜ë¦¬
            elif question.get('has_image'):
                enhanced_q = await self._enhance_image_question(question, context)
                special_questions.append(enhanced_q)
            else:
                special_questions.append(question)
        
        return special_questions
    
    async def _enhance_table_question(self, question: Dict, context: Dict[str, Any]) -> Dict:
        """í‘œê°€ ìˆëŠ” ë¬¸ì œ ê°œì„  ì²˜ë¦¬"""
        
        # í¬ë¡œìŠ¤ í˜ì´ì§€ í‘œ ì •ë³´ í™•ì¸
        table_elements = [elem for elem in context.get("cross_page_elements", []) 
                         if elem["element_type"] == "table"]
        
        if table_elements:
            print(f"      ğŸ“Š ë¬¸ì œ {question.get('question_number')}ë²ˆ: í¬ë¡œìŠ¤ í˜ì´ì§€ í‘œ ì²˜ë¦¬")
            # í‘œ ë°ì´í„°ë¥¼ ì™„ì „íˆ ì¬êµ¬ì„±
            complete_table = self._reconstruct_table(question, table_elements)
            question["passage"] = complete_table
            
            # í‘œ ì´ë¯¸ì§€ë„ ì €ì¥
            table_image_path = await self._extract_table_as_image(question, context)
            if table_image_path:
                question["table_image_path"] = table_image_path
        
        return question
    
    def _reconstruct_table(self, question: Dict, table_elements: List[Dict]) -> str:
        """í¬ë¡œìŠ¤ í˜ì´ì§€ í‘œ ì¬êµ¬ì„±"""
        
        passage = question.get("passage", "")
        
        # í‘œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¬êµ¬ì„±
        if "í”„ë¡œì„¸ìŠ¤" in passage and "ë„ì°©ì‹œê°„" in passage:
            # ìŠ¤ì¼€ì¤„ë§ í‘œ íŒ¨í„´
            table_data = self._extract_scheduling_table_data(passage, table_elements)
            return self._format_as_markdown_table(table_data)
        
        return passage
    
    def _extract_scheduling_table_data(self, passage: str, table_elements: List[Dict]) -> Dict:
        """ìŠ¤ì¼€ì¤„ë§ í‘œ ë°ì´í„° ì¶”ì¶œ"""
        
        # í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
        lines = passage.split('\n')
        header = ["í”„ë¡œì„¸ìŠ¤", "ë„ì°©ì‹œê°„", "ì‹¤í–‰ì‹œê°„"]
        
        data_rows = []
        for line in lines:
            if re.search(r'P\d+', line):  # P1, P2, P3 íŒ¨í„´
                parts = re.findall(r'P\d+|\d+', line)
                if len(parts) >= 3:
                    data_rows.append(parts[:3])
        
        # í¬ë¡œìŠ¤ í˜ì´ì§€ì—ì„œ ëˆ„ë½ëœ ë°ì´í„° ë³´ì™„
        for element in table_elements:
            additional_data = element["partial_content"].get("table_info", {})
            # ì¶”ê°€ ë°ì´í„° ì²˜ë¦¬ ë¡œì§
        
        return {
            "header": header,
            "rows": data_rows
        }
    
    def _format_as_markdown_table(self, table_data: Dict) -> str:
        """ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        if not table_data.get("header") or not table_data.get("rows"):
            return ""
        
        # í—¤ë”
        header_row = " | ".join(table_data["header"])
        separator = " | ".join(["---"] * len(table_data["header"]))
        
        # ë°ì´í„° í–‰ë“¤
        data_rows = []
        for row in table_data["rows"]:
            data_row = " | ".join(str(cell) for cell in row)
            data_rows.append(data_row)
        
        # ì™„ì„±ëœ í‘œ
        table = f"| {header_row} |\n| {separator} |\n"
        for data_row in data_rows:
            table += f"| {data_row} |\n"
        
        return table
    
    async def _extract_table_as_image(self, question: Dict, context: Dict[str, Any]) -> Optional[str]:
        """í‘œë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ì—¬ ì €ì¥"""
        
        # ë¬¸ì œì˜ Y ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ ì˜ì—­ì˜ ì´ë¯¸ì§€ ì¶”ì¶œ
        y_position = question.get("y_position", 0)
        
        if y_position > 0:
            # í†µí•© ì´ë¯¸ì§€ì—ì„œ í•´ë‹¹ ì˜ì—­ ì¶”ì¶œ
            full_image = Image.open(context["combined_image_path"])
            
            # í‘œ ì˜ì—­ ì¶”ì • (Y ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì•„ë˜ 200px ì—¬ìœ )
            crop_area = (0, max(0, y_position - 200), full_image.width, min(full_image.height, y_position + 400))
            table_image = full_image.crop(crop_area)
            
            # ì €ì¥
            assets_dir = Path(context["assets_dir"])
            table_path = assets_dir / f"q{question.get('question_number', 'unknown')}_table.png"
            table_image.save(table_path)
            
            return str(table_path)
        
        return None
    
    async def _enhance_code_question(self, question: Dict, context: Dict[str, Any]) -> Dict:
        """ì½”ë“œê°€ ìˆëŠ” ë¬¸ì œ ê°œì„  ì²˜ë¦¬"""
        
        print(f"      ğŸ’» ë¬¸ì œ {question.get('question_number')}ë²ˆ: ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬")
        
        # ì½”ë“œ ì´ë¯¸ì§€ ì¶”ì¶œ
        code_image_path = await self._extract_code_as_image(question, context)
        if code_image_path:
            question["code_image_path"] = code_image_path
        
        return question
    
    async def _extract_code_as_image(self, question: Dict, context: Dict[str, Any]) -> Optional[str]:
        """ì½”ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ì—¬ ì €ì¥"""
        
        # í‘œì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì½”ë“œ ì˜ì—­ ì¶”ì¶œ
        y_position = question.get("y_position", 0)
        
        if y_position > 0:
            full_image = Image.open(context["combined_image_path"])
            crop_area = (0, max(0, y_position - 100), full_image.width, min(full_image.height, y_position + 300))
            code_image = full_image.crop(crop_area)
            
            assets_dir = Path(context["assets_dir"])
            code_path = assets_dir / f"q{question.get('question_number', 'unknown')}_code.png"
            code_image.save(code_path)
            
            return str(code_path)
        
        return None
    
    async def _enhance_image_question(self, question: Dict, context: Dict[str, Any]) -> Dict:
        """ì´ë¯¸ì§€ê°€ ìˆëŠ” ë¬¸ì œ ê°œì„  ì²˜ë¦¬"""
        
        print(f"      ğŸ–¼ï¸ ë¬¸ì œ {question.get('question_number')}ë²ˆ: ì´ë¯¸ì§€ ì²˜ë¦¬")
        
        # ë‹¤ì´ì–´ê·¸ë¨/ê·¸ë¦¼ ì´ë¯¸ì§€ ì¶”ì¶œ
        diagram_image_path = await self._extract_diagram_as_image(question, context)
        if diagram_image_path:
            question["diagram_image_path"] = diagram_image_path
        
        return question
    
    async def _extract_diagram_as_image(self, question: Dict, context: Dict[str, Any]) -> Optional[str]:
        """ë‹¤ì´ì–´ê·¸ë¨ì„ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ì—¬ ì €ì¥"""
        
        y_position = question.get("y_position", 0)
        
        if y_position > 0:
            full_image = Image.open(context["combined_image_path"])
            crop_area = (0, max(0, y_position - 150), full_image.width, min(full_image.height, y_position + 350))
            diagram_image = full_image.crop(crop_area)
            
            assets_dir = Path(context["assets_dir"])
            diagram_path = assets_dir / f"q{question.get('question_number', 'unknown')}_diagram.png"
            diagram_image.save(diagram_path)
            
            return str(diagram_path)
        
        return None
    
    def _finalize_and_validate(self, questions: List[Dict]) -> List[Dict]:
        """5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ì •ë¦¬"""
        
        print("   âœ… ìµœì¢… ê²€ì¦ ë° ì •ë¦¬ ì¤‘...")
        
        # ë¬¸ì œ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        questions.sort(key=lambda q: q.get("question_number", 999))
        
        # ì¤‘ë³µ ì œê±°
        seen_numbers = set()
        unique_questions = []
        
        for q in questions:
            q_num = q.get("question_number")
            if q_num and q_num not in seen_numbers:
                seen_numbers.add(q_num)
                unique_questions.append(q)
        
        # ëˆ„ë½ëœ ë²ˆí˜¸ í™•ì¸
        expected_numbers = set(range(1, 61))
        found_numbers = {q.get("question_number") for q in unique_questions}
        missing = expected_numbers - found_numbers
        
        if missing:
            print(f"   âš ï¸ ëˆ„ë½ëœ ë¬¸ì œ: {sorted(missing)}")
        
        print(f"   ğŸ“Š ìµœì¢… ì •ë¦¬ ì™„ë£Œ: {len(unique_questions)}ê°œ ë¬¸ì œ")
        
        return unique_questions