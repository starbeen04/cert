#!/usr/bin/env python3
"""
ğŸ¯ ë‹¨ìˆœí™”ëœ 3ë‹¨ê³„ PDF ì²˜ë¦¬ ì‹œìŠ¤í…œ
1ë‹¨ê³„: PDF êµ¬ì¡° ë¶„ì„
2ë‹¨ê³„: êµ¬ì¡° ê¸°ë°˜ ì •í™•í•œ ë°ì´í„° ì¶”ì¶œ
"""

import re
import base64
import json
from typing import Dict, List, Optional, Any
import openai
import fitz
import asyncio

class SimplePDFProcessor:
    """ë‹¨ìˆœí™”ëœ PDF ì²˜ë¦¬ê¸°"""
    
    def __init__(self, openai_client: openai.AsyncOpenAI):
        self.openai_client = openai_client
    
    async def process_pdf_simple(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """3ë‹¨ê³„ ë‹¨ìˆœí™”ëœ PDF ì²˜ë¦¬"""
        
        print(f"ğŸ¯ ë‹¨ìˆœí™”ëœ 3ë‹¨ê³„ PDF ì²˜ë¦¬ ì‹œì‘ - Upload {upload_id}")
        print("=" * 60)
        
        try:
            # 1ë‹¨ê³„: PDF êµ¬ì¡° ë¶„ì„
            print("ğŸ“Š 1ë‹¨ê³„: PDF êµ¬ì¡° ë¶„ì„ ì¤‘...")
            structure_info = await self._analyze_pdf_structure(pdf_path, upload_id)
            
            if not structure_info['success']:
                print("âš ï¸ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´ ì²˜ë¦¬")
                # ê¸°ë³¸ êµ¬ì¡°ë¡œ fallback
                structure_info = self._create_default_structure(pdf_path)
                print(f"ğŸ“‹ ê¸°ë³¸ êµ¬ì¡° ì ìš©: {structure_info['basic_info']['total_questions']}ê°œ ë¬¸ì œ ì˜ˆìƒ")
            
            # 2ë‹¨ê³„: êµ¬ì¡° ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ
            print("ğŸ“ 2ë‹¨ê³„: êµ¬ì¡° ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            extraction_result = await self._extract_data_by_structure(pdf_path, structure_info, upload_id)
            
            return {
                "success": True,
                "structure_analysis": structure_info,
                "extraction_result": extraction_result,
                "total_questions": len(extraction_result.get('questions', [])),
                "processing_method": "simple_3_stage"
            }
            
        except Exception as e:
            print(f"âŒ ë‹¨ìˆœ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _analyze_pdf_structure(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """1ë‹¨ê³„: PDF êµ¬ì¡° ë¶„ì„"""
        
        print(f"ğŸ” 1ë‹¨ê³„ êµ¬ì¡° ë¶„ì„ ì‹œì‘ - Upload {upload_id}")
        
        try:
            # ì „ì²´ PDFë¥¼ ë‚®ì€ í•´ìƒë„ë¡œ ì´ë¯¸ì§€í™”
            doc = fitz.open(pdf_path)
            total_pages = len(doc)
            
            # ëª¨ë“  í˜ì´ì§€ë¥¼ 2ë°° í•´ìƒë„ë¡œ ìƒì„±
            images_data = []
            for page_num in range(total_pages):
                page = doc[page_num]
                mat = fitz.Matrix(2, 2)  # 2ë°° í•´ìƒë„
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")
                images_data.append(base64.b64encode(img_data).decode())
                print(f"   ğŸ“„ í˜ì´ì§€ {page_num + 1} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
            
            doc.close()
            
            # êµ¬ì¡° ë¶„ì„ í”„ë¡¬í”„íŠ¸
            structure_prompt = self._create_structure_analysis_prompt(total_pages)
            
            # ëª¨ë“  í˜ì´ì§€ë¥¼ í•œë²ˆì— ë¶„ì„
            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ PDF êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹œí—˜ ë¬¸ì œì§‘ì˜ êµ¬ì¡°ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [{"type": "text", "text": structure_prompt}] +
                              [{"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img}", "detail": "low"}} 
                               for img in images_data]
                }
            ]
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=8000,
                temperature=0.0
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            structure_info = self._parse_structure_analysis(response_text)
            
            print("âœ… 1ë‹¨ê³„ êµ¬ì¡° ë¶„ì„ ì™„ë£Œ")
            return structure_info
            
        except Exception as e:
            print(f"âŒ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _create_structure_analysis_prompt(self, total_pages: int) -> str:
        """êµ¬ì¡° ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸"""
        
        return f"""ğŸ“‹ PDF êµ¬ì¡° ì™„ì „ ë¶„ì„ ({total_pages}í˜ì´ì§€)

ğŸ¯ **í•µì‹¬ ë¶„ì„ ëª©í‘œ**:
1. ë¬¸ì„œ íƒ€ì… íŒë³„ (ë¬¸ì œì§‘/ì´ë¡ ì„œ/í˜¼í•©)
2. ì´ ë¬¸ì œ ê°œìˆ˜ ì •í™• íŒŒì•…
3. ê° ë¬¸ì œë³„ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
4. í˜ì´ì§€ë³„ ì—­í•  ë¶„ì„
5. íŠ¹ìˆ˜ ìš”ì†Œ ìœ„ì¹˜ íŒŒì•…

ğŸ“Š **í•„ìˆ˜ ë¶„ì„ í•­ëª©**:

**1ï¸âƒ£ ê¸°ë³¸ ì •ë³´**:
- ìê²©ì¦ëª…: (ì˜ˆ: ì •ë³´ì²˜ë¦¬ê¸°ì‚¬, ë„¤íŠ¸ì›Œí¬ê´€ë¦¬ì‚¬ ë“±)
- ì´ ë¬¸ì œ ìˆ˜: ì •í™•í•œ ê°œìˆ˜
- ì²« ë¬¸ì œ ë²ˆí˜¸: (ë³´í†µ 1ë²ˆ)
- ë§ˆì§€ë§‰ ë¬¸ì œ ë²ˆí˜¸: (ì‹¤ì œ í™•ì¸ëœ ìµœê³  ë²ˆí˜¸)
- ë¬¸ì„œ íƒ€ì…: practice_test/theory/mixed

**2ï¸âƒ£ í˜ì´ì§€ë³„ ë¶„ì„**:
ê° í˜ì´ì§€ë§ˆë‹¤:
- í˜ì´ì§€ ì—­í• : questions/answers/explanations/theory
- í¬í•¨ëœ ë¬¸ì œ ë²ˆí˜¸: [ì‹œì‘ë²ˆí˜¸-ëë²ˆí˜¸] 
- ë¬¸ì œ ê°œìˆ˜: ì‹¤ì œ ì¹´ìš´íŠ¸
- íŠ¹ìˆ˜ ìš”ì†Œ: tables/images/codes/diagrams

**3ï¸âƒ£ ë¬¸ì œë³„ ìƒì„¸ ë¶„ì„**:
ê° ë¬¸ì œë§ˆë‹¤:
- ë¬¸ì œ ë²ˆí˜¸: ì •í™•í•œ ë²ˆí˜¸
- ì„ íƒì§€ ê°œìˆ˜: 2/3/4/5ê°œ
- ë³´ê¸° ìœ ë¬´: ìˆìŒ/ì—†ìŒ
- ë³´ê¸° í˜•íƒœ: í‘œ/ì½”ë“œ/ë‹¤ì´ì–´ê·¸ë¨/í…ìŠ¤íŠ¸
- í˜ì´ì§€ ê²½ê³„ ì´ìŠˆ: ë‹¤ìŒí˜ì´ì§€ë¡œ ì´ì–´ì§/ì™„ê²°
- íŠ¹ìˆ˜ ìš”ì†Œ: ìˆ˜ì‹/ì˜ì–´/ì´ë¯¸ì§€ ë“±

**4ï¸âƒ£ íŠ¹ìˆ˜ ë¬¸ì œ ì‹ë³„**:
- í‘œê°€ ìˆëŠ” ë¬¸ì œ: [ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸]
- ì½”ë“œê°€ ìˆëŠ” ë¬¸ì œ: [ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸]  
- ë‹¤ì´ì–´ê·¸ë¨ì´ ìˆëŠ” ë¬¸ì œ: [ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸]
- ì´ë¯¸ì§€ ì„ íƒì§€ê°€ ìˆëŠ” ë¬¸ì œ: [ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸]
- í˜ì´ì§€ ê²½ê³„ ë¬¸ì œ: [ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸]

**5ï¸âƒ£ ì„ íƒì§€ ë¶„í¬ ë¶„ì„**:
- 2ê°œ ì„ íƒì§€: [ë¬¸ì œ ë²ˆí˜¸ë“¤]
- 3ê°œ ì„ íƒì§€: [ë¬¸ì œ ë²ˆí˜¸ë“¤]  
- 4ê°œ ì„ íƒì§€: [ë¬¸ì œ ë²ˆí˜¸ë“¤]
- 5ê°œ ì„ íƒì§€: [ë¬¸ì œ ë²ˆí˜¸ë“¤]

ğŸ” **ì •í™•ë„ í•„ìˆ˜ì‚¬í•­**:
- ëª¨ë“  í˜ì´ì§€ë¥¼ ê¼¼ê¼¼íˆ í™•ì¸
- ë¬¸ì œ ë²ˆí˜¸ ëˆ„ë½ ì—†ì´ ì „ì²´ íŒŒì•…
- ë³´ê¸°ì™€ ì„ íƒì§€ ëª…í™•íˆ êµ¬ë¶„
- í˜ì´ì§€ ê²½ê³„ ë¬¸ì œ ì •í™•íˆ ì‹ë³„

ğŸ“¤ **JSON ì¶œë ¥ í˜•ì‹**:
```json
{{
  "basic_info": {{
    "certificate_name": "ìê²©ì¦ëª…",
    "total_questions": ì´ë¬¸ì œìˆ˜,
    "first_question": ì²«ë²ˆí˜¸,
    "last_question": ë§ˆì§€ë§‰ë²ˆí˜¸,
    "document_type": "practice_test",
    "total_pages": {total_pages}
  }},
  "page_analysis": [
    {{
      "page_number": 1,
      "role": "questions",
      "question_range": "1-15",
      "question_count": 15,
      "questions": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],
      "special_elements": ["tables", "codes"],
      "cross_page_issues": []
    }}
  ],
  "question_details": {{
    "1": {{"choices": 4, "has_passage": false, "passage_type": "", "special_elements": [], "page_location": 1}},
    "6": {{"choices": 4, "has_passage": true, "passage_type": "table", "special_elements": ["table"], "page_location": 1}}
  }},
  "special_questions": {{
    "table_questions": [6, 12],
    "code_questions": [24, 33],
    "diagram_questions": [45],
    "cross_page_questions": []
  }},
  "choice_distribution": {{
    "2_choices": [],
    "3_choices": [],
    "4_choices": [1,2,3,4,5,7,8,9,10,11],
    "5_choices": []
  }},
  "success": true
}}
```

âš¡ **ì¤‘ìš”**: ëª¨ë“  ë¬¸ì œë¥¼ ë¹ ì§ì—†ì´ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”!"""

    def _parse_structure_analysis(self, response_text: str) -> Dict[str, Any]:
        """êµ¬ì¡° ë¶„ì„ ì‘ë‹µ íŒŒì‹± (ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        
        print(f"ğŸ” êµ¬ì¡° ë¶„ì„ ì‘ë‹µ ê¸¸ì´: {len(response_text)}ì")
        print(f"ğŸ” ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:200]}...")
        
        try:
            # ë‹¤ì–‘í•œ JSON ë¸”ë¡ íŒ¨í„´ ì‹œë„
            patterns = [
                r'```json\s*(\{[\s\S]*?\})\s*```',
                r'```\s*(\{[\s\S]*?\})\s*```',
                r'(\{[\s\S]*?\})',
            ]
            
            json_str = None
            for pattern in patterns:
                json_match = re.search(pattern, response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                    print(f"âœ… JSON ë¸”ë¡ ë°œê²¬: {len(json_str)}ì")
                    break
            
            if not json_str:
                print("âš ï¸ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return {"success": False, "error": "JSON ë¸”ë¡ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
            
            # JSON ì •ë¦¬ (ì£¼ì„ ì œê±°, ë¹„ì •í˜• ìˆ˜ì •)
            json_str = self._clean_json_string(json_str)
            
            # JSON íŒŒì‹± ì‹œë„
            structure_data = json.loads(json_str)
            structure_data['success'] = True
            
            print("âœ… JSON íŒŒì‹± ì„±ê³µ")
            return structure_data
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"âš ï¸ ë¬¸ì œ ì˜ì—­: {json_str[max(0, e.pos-50):e.pos+50] if json_str and hasattr(e, 'pos') else 'N/A'}")
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "success": False, 
                "error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}",
                "basic_info": {
                    "total_questions": 60,  # ê¸°ë³¸ê°’
                    "document_type": "practice_test"
                }
            }
        
        except Exception as e:
            print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"}
    
    def _clean_json_string(self, json_str: str) -> str:
        """ê¸°ë³¸ì ì¸ JSON ì •ë¦¬"""
        
        # ì£¼ì„ ì œê±°
        json_str = re.sub(r'//.*', '', json_str)
        
        # ì—¬ëŸ¬ ê³µë°± ì •ë¦¬
        json_str = re.sub(r'\s+', ' ', json_str)
        
        # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±°
        json_str = re.sub(r',\s*(\]|\})', r'\1', json_str)
        
        return json_str.strip()
    
    def _create_default_structure(self, pdf_path: str) -> Dict[str, Any]:
        """ê¸°ë³¸ êµ¬ì¡° ìƒì„± (fallback)"""
        
        try:
            # ê¸°ë³¸ PDF ì •ë³´ ì¶”ì¶œ
            doc = fitz.open(pdf_path)
            total_pages = len(doc)
            doc.close()
            
            # ê¸°ë³¸ êµ¬ì¡° ì„¤ì •
            questions_per_page = 15  # í‰ê· 
            estimated_questions = min(80, total_pages * questions_per_page)
            
            return {
                "success": True,
                "basic_info": {
                    "certificate_name": "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬",
                    "total_questions": estimated_questions,
                    "first_question": 1,
                    "last_question": estimated_questions,
                    "document_type": "practice_test",
                    "total_pages": total_pages
                },
                "page_analysis": [
                    {
                        "page_number": i + 1,
                        "role": "questions" if i < total_pages - 2 else "answers",
                        "question_range": f"{i*questions_per_page+1}-{min((i+1)*questions_per_page, estimated_questions)}",
                        "question_count": min(questions_per_page, estimated_questions - i*questions_per_page),
                        "questions": list(range(i*questions_per_page+1, min((i+1)*questions_per_page+1, estimated_questions+1))),
                        "special_elements": [],
                        "cross_page_issues": []
                    }
                    for i in range(total_pages) if i*questions_per_page < estimated_questions
                ],
                "question_details": {
                    str(i): {"choices": 4, "has_passage": False, "passage_type": "", "special_elements": [], "page_location": (i-1)//questions_per_page + 1}
                    for i in range(1, estimated_questions + 1)
                },
                "special_questions": {
                    "table_questions": [],
                    "code_questions": [],
                    "diagram_questions": [],
                    "cross_page_questions": []
                },
                "choice_distribution": {
                    "2_choices": [],
                    "3_choices": [],
                    "4_choices": list(range(1, estimated_questions + 1)),
                    "5_choices": []
                }
            }
        
        except Exception as e:
            print(f"âš ï¸ ê¸°ë³¸ êµ¬ì¡° ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _extract_data_by_structure(self, pdf_path: str, structure_info: Dict, upload_id: int) -> Dict[str, Any]:
        """2ë‹¨ê³„: êµ¬ì¡° ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ"""
        
        print(f"ğŸ“ 2ë‹¨ê³„ ë°ì´í„° ì¶”ì¶œ ì‹œì‘ - Upload {upload_id}")
        
        try:
            questions = []
            page_analysis = structure_info.get('page_analysis', [])
            question_details = structure_info.get('question_details', {})
            
            # ë¬¸ì œê°€ ìˆëŠ” í˜ì´ì§€ë§Œ ì²˜ë¦¬
            question_pages = [page for page in page_analysis if page.get('role') == 'questions']
            
            for page_info in question_pages:
                page_num = page_info['page_number']
                page_questions = page_info.get('questions', [])
                
                if not page_questions:
                    continue
                
                print(f"   ğŸ“„ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ({len(page_questions)}ê°œ ë¬¸ì œ)...")
                
                # í˜ì´ì§€ë³„ ê³ í•´ìƒë„ ì¶”ì¶œ
                page_questions_data = await self._extract_page_questions(
                    pdf_path, page_num, page_questions, question_details
                )
                
                questions.extend(page_questions_data)
            
            print(f"âœ… 2ë‹¨ê³„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(questions)}ê°œ ë¬¸ì œ")
            
            return {
                "success": True,
                "questions": questions,
                "total_extracted": len(questions),
                "extraction_method": "structure_based"
            }
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _extract_page_questions(self, pdf_path: str, page_num: int, question_numbers: List[int], question_details: Dict) -> List[Dict]:
        """í˜ì´ì§€ë³„ ë¬¸ì œ ì¶”ì¶œ"""
        
        try:
            # ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±
            doc = fitz.open(pdf_path)
            page = doc[page_num - 1]  # 0-based index
            mat = fitz.Matrix(8, 8)  # 8ë°° í•´ìƒë„
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            doc.close()
            
            # ë¬¸ì œë³„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            special_questions = []
            regular_questions = []
            
            for q_num in question_numbers:
                q_detail = question_details.get(str(q_num), {})
                if q_detail.get('special_elements') or q_detail.get('has_passage'):
                    special_questions.append(q_num)
                else:
                    regular_questions.append(q_num)
            
            # ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            extraction_prompt = self._create_extraction_prompt(question_numbers, question_details)
            
            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì •í™•í•œ ë¬¸ì œ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. êµ¬ì¡° ë¶„ì„ ì •ë³´ì— ë”°ë¼ ê° ë¬¸ì œë¥¼ ì™„ë²½íˆ ì¶”ì¶œí•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": extraction_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64.b64encode(img_data).decode()}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=10000,
                temperature=0.0
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            questions_data = self._parse_extraction_result(response_text)
            
            return questions_data
            
        except Exception as e:
            print(f"   âŒ í˜ì´ì§€ {page_num} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _create_extraction_prompt(self, question_numbers: List[int], question_details: Dict) -> str:
        """ë°ì´í„° ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸"""
        
        # ë¬¸ì œë³„ ìƒì„¸ ì •ë³´ ì •ë¦¬
        question_info_text = ""
        for q_num in question_numbers:
            detail = question_details.get(str(q_num), {})
            choices_count = detail.get('choices', 4)
            has_passage = detail.get('has_passage', False)
            passage_type = detail.get('passage_type', '')
            special_elements = detail.get('special_elements', [])
            
            question_info_text += f"- ë¬¸ì œ {q_num}ë²ˆ: {choices_count}ê°œ ì„ íƒì§€"
            if has_passage:
                question_info_text += f", ë³´ê¸°({passage_type})"
            if special_elements:
                question_info_text += f", íŠ¹ìˆ˜ìš”ì†Œ({', '.join(special_elements)})"
            question_info_text += "\n"
        
        return f"""ğŸ“ ì •í™•í•œ ë¬¸ì œ ë°ì´í„° ì¶”ì¶œ

ğŸ¯ **ì¶”ì¶œ ëŒ€ìƒ**: {len(question_numbers)}ê°œ ë¬¸ì œ
{question_info_text}

ğŸ“‹ **ì¶”ì¶œ ì§€ì¹¨**:
1. ê° ë¬¸ì œë¥¼ ì •í™•í•œ ë²ˆí˜¸ì™€ í•¨ê»˜ ì¶”ì¶œ
2. ë¬¸ì œ ì§€ë¬¸ê³¼ ì„ íƒì§€ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
3. ë³´ê¸°ê°€ ìˆëŠ” ë¬¸ì œëŠ” ë³´ê¸°ë¥¼ ë³„ë„ ì¶”ì¶œ
4. íŠ¹ìˆ˜ ìš”ì†Œ(í‘œ/ì½”ë“œ/ë‹¤ì´ì–´ê·¸ë¨)ëŠ” ì™„ì „íˆ ë³´ì¡´
5. ì„ íƒì§€ ë§ˆì»¤(â‘ â‘¡â‘¢â‘£)ë¥¼ ì •í™•íˆ ìœ ì§€

âš ï¸ **ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­**:
- ë¬¸ì œ ë²ˆí˜¸ ë³€ê²½ ê¸ˆì§€
- ì„ íƒì§€ ë‚´ìš© ìˆ˜ì • ê¸ˆì§€  
- ìˆ«ìë‚˜ ê¸°í˜¸ ì„ì˜ ë³€ê²½ ê¸ˆì§€
- ë³´ê¸°ì™€ ì„ íƒì§€ í˜¼ë™ ê¸ˆì§€

ğŸ“¤ **JSON ì¶œë ¥ í˜•ì‹**:
```json
{{
  "questions": [
    {{
      "question_number": 1,
      "question_text": "ì •í™•í•œ ë¬¸ì œ ì§€ë¬¸",
      "passage": "ë³´ê¸° ë‚´ìš© (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
      "options": ["â‘  ì„ íƒì§€1", "â‘¡ ì„ íƒì§€2", "â‘¢ ì„ íƒì§€3", "â‘£ ì„ íƒì§€4"],
      "page_number": í˜ì´ì§€ë²ˆí˜¸,
      "has_table": false,
      "has_code": false,
      "has_diagram": false,
      "extraction_confidence": "high"
    }}
  ]
}}
```

ğŸ” **ì •í™•ì„± í™•ì¸**:
- ëª¨ë“  ë¬¸ì œ ë²ˆí˜¸ê°€ ìš”ì²­í•œ ë²ˆí˜¸ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- ì„ íƒì§€ ê°œìˆ˜ê°€ êµ¬ì¡° ë¶„ì„ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- íŠ¹ìˆ˜ ìš”ì†Œê°€ ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸"""

    def _parse_extraction_result(self, response_text: str) -> List[Dict]:
        """ì¶”ì¶œ ê²°ê³¼ íŒŒì‹±"""
        
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                result_data = json.loads(json_str)
                return result_data.get('questions', [])
            else:
                print("âš ï¸ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return []
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []