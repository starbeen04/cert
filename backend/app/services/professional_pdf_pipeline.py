#!/usr/bin/env python3
"""
ğŸš€ ì‹¤ì „ íŒŒì´í”„ë¼ì¸: PDF êµ¬ì¡°íŒŒì•… â†’ ì •ê·œìŠ¤í‚¤ë§ˆ ì €ì¥ â†’ LLM ìœ í˜•/ì±•í„° íƒœê¹…
ì‚¬ìš©ì ì œì‹œ ìš”êµ¬ì‚¬í•­ì„ ì™„ì „ ë°˜ì˜í•œ ì „ë¬¸ì  ì²˜ë¦¬ ì‹œìŠ¤í…œ
"""

import re
import json
import base64
from PIL import Image
import io
import os
import asyncio
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import fitz  # PyMuPDF
import openai
from datetime import datetime
import csv
import uuid

class ProfessionalPDFPipeline:
    """ì‹¤ì „ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, openai_client: openai.AsyncOpenAI):
        self.openai_client = openai_client
        
        # ì‹¤ì œ PDFì—ì„œ ê°ì§€ëœ ê·œì¹™ ì ìš©
        self.PDF_RULES = {
            "total_questions": 60,
            "choices_per_question": 4,
            "choice_markers": ["â‘ ", "â‘¡", "â‘¢", "â‘£"],
            "subjects": {
                "1-20": "ì •ë³´ì‹œìŠ¤í…œ ê¸°ë°˜ ê¸°ìˆ ", 
                "21-40": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ í™œìš©",
                "41-60": "ë°ì´í„°ë² ì´ìŠ¤ í™œìš©"
            },
            "special_questions": {
                "table": [6],      # ìŠ¤ì¼€ì¤„ë§ í‘œ
                "image_choices": [15],  # ERD ê¸°í˜¸ (ì„ íƒì§€ê°€ ì´ë¯¸ì§€)
                "code": [24, 33, 40],   # Java ì½”ë“œ ë¸”ë¡
                "diagram": [56]    # íŠ¸ë¦¬ ê·¸ë¦¼
            },
            "pages": {
                "questions": [1, 2, 3, 4],  # ë¬¸ì œ í˜ì´ì§€
                "answers": [5, 6, 7, 8]     # ì •ë‹µ/í•´ì„¤ í˜ì´ì§€
            }
        }
    
    async def process_pdf_professional(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """ì‹¤ì „ íŒŒì´í”„ë¼ì¸ ë©”ì¸ ì²˜ë¦¬"""
        
        print(f"ğŸš€ ì‹¤ì „ íŒŒì´í”„ë¼ì¸ ì‹œì‘ - Upload {upload_id}")
        print("=" * 80)
        
        try:
            # === Aë‹¨ê³„: êµ¬ì¡° íŒŒì•… ===
            print("ğŸ“‹ Aë‹¨ê³„: PDF êµ¬ì¡° íŒŒì•… ì‹œì‘")
            structure_data = await self._stage_a_structure_analysis(pdf_path, upload_id)
            
            if not structure_data["success"]:
                return {"success": False, "error": "Aë‹¨ê³„ êµ¬ì¡° íŒŒì•… ì‹¤íŒ¨"}
            
            # === Bë‹¨ê³„: ì •ê·œ ìŠ¤í‚¤ë§ˆ ì €ì¥ ===
            print("ğŸ“Š Bë‹¨ê³„: ì •ê·œ ìŠ¤í‚¤ë§ˆ ì €ì¥ ì‹œì‘")
            schema_result = await self._stage_b_schema_storage(structure_data, upload_id)
            
            if not schema_result["success"]:
                return {"success": False, "error": "Bë‹¨ê³„ ìŠ¤í‚¤ë§ˆ ì €ì¥ ì‹¤íŒ¨"}
            
            # === Cë‹¨ê³„: LLM ìœ í˜•/ì±•í„° íƒœê¹… ===
            print("ğŸ·ï¸ Cë‹¨ê³„: LLM ìœ í˜•/ì±•í„° íƒœê¹… ì‹œì‘")
            tagging_result = await self._stage_c_llm_tagging(schema_result, upload_id)
            
            print("âœ… ì‹¤ì „ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            return {
                "success": True,
                "structure_data": structure_data,
                "schema_result": schema_result,
                "tagging_result": tagging_result,
                "total_questions": len(schema_result.get("questions", [])),
                "processing_method": "professional_pipeline"
            }
            
        except Exception as e:
            print(f"âŒ ì‹¤ì „ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _stage_a_structure_analysis(self, pdf_path: str, upload_id: int) -> Dict[str, Any]:
        """Aë‹¨ê³„: êµ¬ì¡° íŒŒì•… ë‹¨ê³„"""
        
        print("ğŸ” A-1: í˜ì´ì§€/ì´ë¯¸ì§€ ì¤€ë¹„")
        assets_dir = Path(f"assets/upload_{upload_id}")
        assets_dir.mkdir(parents=True, exist_ok=True)
        
        # A-1: PDF â†’ í˜ì´ì§€ ì´ë¯¸ì§€ (300dpi)
        pages_data = await self._prepare_pages_and_images(pdf_path, assets_dir)
        
        print("ğŸ” A-2: ë¬¸í•­/ì´ë¡  êµ¬ë¶„")
        # A-2: Q/A í˜ì´ì§€ vs í•´ì„¤ í˜ì´ì§€ êµ¬ë¶„
        page_classification = self._classify_pages(pages_data)
        
        print("ğŸ” A-3: ë¬¸í•­ ë¸”ë¡ ì„¸ê·¸ë¨¼íŠ¸")
        # A-3: ë¬¸í•­ ë¸”ë¡ ì„¸ê·¸ë¨¼íŠ¸
        question_blocks = await self._segment_question_blocks(pages_data, page_classification)
        
        print("ğŸ” A-4: ê³¼ëª©/ìê²©ì¦ ì‹ë³„")
        # A-4: ê³¼ëª©/ìê²©ì¦Â·ì‹œí—˜ëª… ì‹ë³„
        exam_info = self._identify_exam_info(pages_data)
        
        print("ğŸ” A-5: ë³´ê¸° ë° íŠ¹ìˆ˜ ìš”ì†Œ ê°ì§€")
        # A-5: 'ë³´ê¸°'(passage) ë° íŠ¹ìˆ˜ ìš”ì†Œ ê°ì§€
        special_elements = await self._detect_special_elements(question_blocks, assets_dir)
        
        print("ğŸ” A-6: ì„ íƒì§€ ìˆ˜/í¬ë¡œìŠ¤ í˜ì´ì§€ íŒì •")
        # A-6: ì„ íƒì§€ ìˆ˜/í˜ì´ì§€ ë„˜ì–´ê° íŒì •
        choice_analysis = self._analyze_choices_and_cross_page(question_blocks)
        
        print("ğŸ” A-7: ì •ë‹µí‘œ/í•´ì„¤ íŒŒì‹±")
        # A-7: ì •ë‹µí‘œ/í•´ì„¤ íŒŒì‹± & ê²€ì¦
        answers_explanations = self._parse_answers_and_explanations(pages_data, page_classification)
        
        return {
            "success": True,
            "upload_id": upload_id,
            "assets_dir": str(assets_dir),
            "pages_data": pages_data,
            "page_classification": page_classification,
            "question_blocks": question_blocks,
            "exam_info": exam_info,
            "special_elements": special_elements,
            "choice_analysis": choice_analysis,
            "answers_explanations": answers_explanations
        }
    
    async def _prepare_pages_and_images(self, pdf_path: str, assets_dir: Path) -> Dict[str, Any]:
        """A-1: í˜ì´ì§€ ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸+ì¢Œí‘œ ì¶”ì¶œ"""
        
        doc = fitz.open(pdf_path)
        pages_data = {
            "total_pages": len(doc),
            "pages": []
        }
        
        # í˜ì´ì§€ë³„ ì²˜ë¦¬
        for page_num in range(len(doc)):
            page = doc[page_num]
            page_info = {
                "page_number": page_num + 1,
                "image_path": None,
                "layout_data": None,
                "raw_text": page.get_text(),
                "text_blocks": []
            }
            
            # 300dpi PNG ìƒì„±
            mat = fitz.Matrix(4.17, 4.17)  # 300dpi â‰ˆ 4.17ë°°
            pix = page.get_pixmap(matrix=mat)
            
            page_image_path = assets_dir / "pages" / f"page_{page_num+1:02d}.png"
            page_image_path.parent.mkdir(exist_ok=True)
            pix.save(str(page_image_path))
            page_info["image_path"] = str(page_image_path)
            
            # í…ìŠ¤íŠ¸+ì¢Œí‘œ ì¶”ì¶œ
            text_dict = page.get_text("dict")
            layout_data = []
            
            for block in text_dict["blocks"]:
                if "lines" in block:
                    for line in block["lines"]:
                        for span in line["spans"]:
                            layout_data.append({
                                "text": span["text"],
                                "bbox": span["bbox"],  # [x0, y0, x1, y1]
                                "font": span["font"],
                                "size": span["size"],
                                "flags": span["flags"]
                            })
            
            # ë ˆì´ì•„ì›ƒ JSON ì €ì¥
            layout_path = assets_dir / "layout" / f"page_{page_num+1}.json"
            layout_path.parent.mkdir(exist_ok=True)
            with open(layout_path, 'w', encoding='utf-8') as f:
                json.dump(layout_data, f, ensure_ascii=False, indent=2)
            
            page_info["layout_data"] = str(layout_path)
            page_info["text_blocks"] = [item["text"] for item in layout_data]
            
            pages_data["pages"].append(page_info)
            print(f"   ğŸ“„ í˜ì´ì§€ {page_num+1} ì²˜ë¦¬ ì™„ë£Œ: {len(layout_data)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡")
        
        doc.close()
        return pages_data
    
    def _classify_pages(self, pages_data: Dict[str, Any]) -> Dict[str, Any]:
        """A-2: ë¬¸í•­/ì´ë¡  êµ¬ë¶„ (Q/A í˜ì´ì§€ vs í•´ì„¤ í˜ì´ì§€)"""
        
        classification = {
            "question_pages": [],
            "answer_pages": [],
            "explanation_pages": []
        }
        
        # ì‹¤ì œ PDF ê·œì¹™ ì ìš©
        for page_info in pages_data["pages"]:
            page_num = page_info["page_number"]
            text = page_info["raw_text"]
            
            # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜
            if page_num in self.PDF_RULES["pages"]["questions"]:
                classification["question_pages"].append(page_num)
            elif page_num in self.PDF_RULES["pages"]["answers"]:
                # "ì •ë‹µ ë° í•´ì„¤" í‚¤ì›Œë“œë¡œ ì¬ê²€ì¦
                if "ì •ë‹µ" in text and "í•´ì„¤" in text:
                    classification["answer_pages"].append(page_num)
                else:
                    classification["explanation_pages"].append(page_num)
        
        print(f"   ğŸ“‹ í˜ì´ì§€ ë¶„ë¥˜: ë¬¸ì œ {classification['question_pages']}, ì •ë‹µ/í•´ì„¤ {classification['answer_pages'] + classification['explanation_pages']}")
        return classification
    
    async def _segment_question_blocks(self, pages_data: Dict[str, Any], classification: Dict[str, Any]) -> List[Dict[str, Any]]:
        """A-3: ë¬¸í•­ ë¸”ë¡ ì„¸ê·¸ë¨¼íŠ¸ - 2ë‹¨ê³„ ì •ë°€ ë¶„ì„"""
        
        # 1ë‹¨ê³„: ê° í˜ì´ì§€ë³„ ì´ˆê¸° ë¶„ì„
        all_questions = []
        page_questions_map = {}
        
        for page_info in pages_data["pages"]:
            if page_info["page_number"] not in classification["question_pages"]:
                continue
                
            print(f"   ğŸ” í˜ì´ì§€ {page_info['page_number']} 1ì°¨ Vision ë¶„ì„ ì¤‘...")
            page_questions = await self._analyze_page_with_vision(page_info)
            all_questions.extend(page_questions)
            page_questions_map[page_info['page_number']] = page_questions
        
        print(f"   ğŸ“Š 1ì°¨ ë¶„ì„ ì™„ë£Œ: {len(all_questions)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
        
        # 2ë‹¨ê³„: ëˆ„ë½/ì˜¤ë¥˜ ê²€ì¦ ë° ì¬ë¶„ì„
        verified_questions = await self._verify_and_fix_questions(all_questions, pages_data, classification)
        
        print(f"   ğŸ“ ìµœì¢… ë¬¸í•­ ë¸”ë¡: {len(verified_questions)}ê°œ ë¬¸ì œ")
        return verified_questions
    
    async def _verify_and_fix_questions(self, questions: List[Dict], pages_data: Dict, classification: Dict) -> List[Dict]:
        """2ë‹¨ê³„: ëˆ„ë½/ì˜¤ë¥˜ ë¬¸ì œ ê²€ì¦ ë° ìˆ˜ì •"""
        
        print(f"   ğŸ” 2ë‹¨ê³„: ë¬¸ì œ ê²€ì¦ ë° ë³´ì™„ ì‹œì‘")
        
        # 1. ë¬¸ì œ ë²ˆí˜¸ ë¶„ì„
        found_numbers = {q['question_number'] for q in questions}
        expected_numbers = set(range(1, 61))  # 1-60ë²ˆ ë¬¸ì œ
        missing_numbers = expected_numbers - found_numbers
        
        if missing_numbers:
            print(f"      ğŸš¨ ëˆ„ë½ëœ ë¬¸ì œ: {sorted(missing_numbers)}")
            
            # ëˆ„ë½ëœ ë¬¸ì œë“¤ ì¬ë¶„ì„
            for missing_num in sorted(missing_numbers):
                recovered_question = await self._recover_missing_question(missing_num, pages_data, classification)
                if recovered_question:
                    questions.append(recovered_question)
                    print(f"      âœ… ë¬¸ì œ {missing_num}ë²ˆ ë³µêµ¬ ì™„ë£Œ")
        
        # 2. í¬ë¡œìŠ¤ í˜ì´ì§€ ë¬¸ì œ ì²˜ë¦¬
        questions = await self._fix_cross_page_questions(questions, pages_data)
        
        # 3. íŠ¹ìˆ˜ ìš”ì†Œ ê°„ë‹¨ ê²€ì¦ (í‘œ, ë‹¤ì´ì–´ê·¸ë¨, ì½”ë“œ)
        questions = await self._enhance_special_elements(questions, pages_data)
        
        # 4. ë¬¸ì œ ë²ˆí˜¸ìˆœìœ¼ë¡œ ì •ë ¬
        questions = sorted(questions, key=lambda q: q.get('question_number', 999))
        print(f"      ğŸ“Š ë¬¸ì œ ë²ˆí˜¸ìˆœ ì •ë ¬ ì™„ë£Œ: {len(questions)}ê°œ ë¬¸ì œ")
        
        return questions
    
    async def _recover_missing_question(self, question_num: int, pages_data: Dict, classification: Dict) -> Optional[Dict]:
        """ëˆ„ë½ëœ ë¬¸ì œ ë³µêµ¬ - ë‹¤ë‹¨ê³„ ë³µêµ¬ ì „ëµ"""
        
        print(f"      ğŸ” ë¬¸ì œ {question_num}ë²ˆ ë‹¤ë‹¨ê³„ ë³µêµ¬ ì‹œì‘...")
        
        # ì „ëµ 1: ì •í™•í•œ í˜ì´ì§€ì—ì„œ íƒìƒ‰
        primary_page = self._get_primary_page_for_question(question_num)
        result = await self._try_recover_from_page(question_num, primary_page, pages_data)
        if result:
            print(f"      âœ… ì „ëµ 1 ì„±ê³µ: í˜ì´ì§€ {primary_page}ì—ì„œ ë¬¸ì œ {question_num}ë²ˆ ë³µêµ¬")
            return result
        
        # ì „ëµ 2: ì¸ì ‘ í˜ì´ì§€ë“¤ì—ì„œ íƒìƒ‰
        adjacent_pages = self._get_adjacent_pages(primary_page, pages_data)
        for page_num in adjacent_pages:
            print(f"      ğŸ”„ ì „ëµ 2: ì¸ì ‘ í˜ì´ì§€ {page_num}ì—ì„œ íƒìƒ‰ ì¤‘...")
            result = await self._try_recover_from_page(question_num, page_num, pages_data)
            if result:
                print(f"      âœ… ì „ëµ 2 ì„±ê³µ: í˜ì´ì§€ {page_num}ì—ì„œ ë¬¸ì œ {question_num}ë²ˆ ë³µêµ¬")
                return result
        
        # ì „ëµ 3: ëª¨ë“  ë¬¸ì œ í˜ì´ì§€ì—ì„œ ì™„ì „ ì¬ìŠ¤ìº”
        print(f"      ğŸ”„ ì „ëµ 3: ëª¨ë“  ë¬¸ì œ í˜ì´ì§€ ì™„ì „ ì¬ìŠ¤ìº”...")
        for page_info in pages_data["pages"]:
            if page_info["page_number"] in classification["question_pages"]:
                result = await self._deep_scan_for_question(question_num, page_info)
                if result:
                    print(f"      âœ… ì „ëµ 3 ì„±ê³µ: í˜ì´ì§€ {page_info['page_number']}ì—ì„œ ë¬¸ì œ {question_num}ë²ˆ ë³µêµ¬")
                    return result
        
        print(f"      âŒ ëª¨ë“  ë³µêµ¬ ì „ëµ ì‹¤íŒ¨: ë¬¸ì œ {question_num}ë²ˆ")
        return None
    
    def _get_primary_page_for_question(self, question_num: int) -> int:
        """ë¬¸ì œ ë²ˆí˜¸ì— ë”°ë¥¸ ì£¼ìš” í˜ì´ì§€ ì¶”ì •"""
        if 1 <= question_num <= 15:
            return 1
        elif 16 <= question_num <= 30:
            return 2
        elif 31 <= question_num <= 45:
            return 3
        else:
            return 4
    
    def _get_adjacent_pages(self, primary_page: int, pages_data: Dict) -> List[int]:
        """ì¸ì ‘ í˜ì´ì§€ë“¤ ë°˜í™˜"""
        max_page = pages_data["total_pages"]
        adjacent = []
        
        # ì´ì „/ë‹¤ìŒ í˜ì´ì§€ ì¶”ê°€
        if primary_page > 1:
            adjacent.append(primary_page - 1)
        if primary_page < max_page:
            adjacent.append(primary_page + 1)
        
        return adjacent
    
    async def _try_recover_from_page(self, question_num: int, page_num: int, pages_data: Dict) -> Optional[Dict]:
        """íŠ¹ì • í˜ì´ì§€ì—ì„œ ë¬¸ì œ ë³µêµ¬ ì‹œë„"""
        page_info = None
        for page in pages_data["pages"]:
            if page["page_number"] == page_num:
                page_info = page
                break
        
        if not page_info:
            return None
        
        return await self._analyze_specific_question(page_info, question_num)
    
    async def _deep_scan_for_question(self, question_num: int, page_info: Dict) -> Optional[Dict]:
        """í˜ì´ì§€ ë‚´ ì‹¬ì¸µ ìŠ¤ìº”ìœ¼ë¡œ ë¬¸ì œ íƒìƒ‰"""
        image_path = page_info["image_path"]
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ë” ê°•ë ¥í•œ íƒìƒ‰ í”„ë¡¬í”„íŠ¸
        deep_prompt = f"""ğŸ” **ì´ˆì •ë°€ ë¬¸ì œ íƒìƒ‰ ëª¨ë“œ**

ì´ í˜ì´ì§€ì—ì„œ ë¬¸ì œ {question_num}ë²ˆì„ ë°˜ë“œì‹œ ì°¾ì•„ì£¼ì„¸ìš”.

**íƒìƒ‰ ì§€ì¹¨:**
1. "{question_num}." ë˜ëŠ” "{question_num}ë²ˆ" íŒ¨í„´ ì •ë°€ íƒìƒ‰
2. ìˆ«ìê°€ íë¦¿í•˜ê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œ ë³´ì´ëŠ” ê²½ìš°ë„ ê³ ë ¤
3. ë‹¤ë¥¸ ë¬¸ì œë“¤ ì‚¬ì´ì— ìˆ¨ì–´ìˆì„ ìˆ˜ ìˆìŒ
4. í˜ì´ì§€ ê°€ì¥ìë¦¬ë‚˜ êµ¬ì„ì§„ ê³³ë„ í™•ì¸
5. í‘œë‚˜ ê·¸ë¦¼ ì•ˆì— í¬í•¨ëœ ê²½ìš°ë„ í™•ì¸

**íŠ¹ë³„ ì£¼ì˜ì‚¬í•­:**
- ìˆ«ì 4ì™€ 9, 6ê³¼ 8, 2ì™€ 3 êµ¬ë³„ì— íŠ¹ë³„ ì£¼ì˜
- ë¬¸ì œ ë²ˆí˜¸ê°€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ì™€ ê²¹ì³ ë³´ì¼ ìˆ˜ ìˆìŒ
- ì„ íƒì§€ â‘ â‘¡â‘¢â‘£ê°€ ìˆëŠ” ë¬¸ì œë§Œ ì¶”ì¶œ

ë¬¸ì œë¥¼ ì°¾ìœ¼ë©´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
```json
{{
    "question_number": {question_num},
    "question_text": "ë¬¸ì œ ë‚´ìš©",
    "choices": [
        {{"marker": "â‘ ", "content": "ì„ íƒì§€1"}},
        {{"marker": "â‘¡", "content": "ì„ íƒì§€2"}},
        {{"marker": "â‘¢", "content": "ì„ íƒì§€3"}},
        {{"marker": "â‘£", "content": "ì„ íƒì§€4"}}
    ],
    "passage": "",
    "has_table": false,
    "has_image": false,
    "has_code": false,
    "confidence": "high"
}}
```

ë¬¸ì œê°€ ì—†ë‹¤ë©´ nullì„ ë°˜í™˜í•˜ì„¸ìš”."""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ì´ˆì •ë°€ ë¬¸ì œ íƒìƒ‰ ì „ë¬¸ê°€. ì£¼ì–´ì§„ í˜ì´ì§€ì—ì„œ íŠ¹ì • ë¬¸ì œ ë²ˆí˜¸ë¥¼ ë°˜ë“œì‹œ ì°¾ì•„ë‚´ì•¼ í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": [
                        {"type": "text", "text": deep_prompt},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/png;base64,{image_data}",
                            "detail": "high"
                        }}
                    ]}
                ],
                max_tokens=2000,
                temperature=0.05  # ë§¤ìš° ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í™•ë³´
            )
            
            response_text = response.choices[0].message.content
            
            if "null" in response_text.lower() or "ì—†" in response_text:
                return None
            
            result = self._parse_questions_json(response_text)
            
            if result and 'question_number' in result:
                result["page_number"] = page_info["page_number"]
                return result
            elif result and 'questions' in result and result['questions']:
                question_data = result["questions"][0]
                question_data["page_number"] = page_info["page_number"]
                return question_data
                
            return None
            
        except Exception as e:
            print(f"      âŒ ì‹¬ì¸µ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            return None
    
    async def _analyze_specific_question(self, page_info: Dict, target_question_num: int) -> Optional[Dict]:
        """íŠ¹ì • ë¬¸ì œ ë²ˆí˜¸ì— ì§‘ì¤‘í•œ ë¶„ì„"""
        
        image_path = page_info["image_path"]
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        prompt = f"""ì´ í˜ì´ì§€ì—ì„œ ë¬¸ì œ {target_question_num}ë²ˆë§Œ ì •í™•íˆ ì°¾ì•„ì„œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.

í˜ì´ì§€ì—ì„œ "{target_question_num}."ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì œë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

```json
{{
  "question_number": {target_question_num},
  "question_text": "ë¬¸ì œ {target_question_num}ë²ˆì˜ ì „ì²´ ë‚´ìš©",
  "choices": [
    {{"marker": "â‘ ", "content": "ì„ íƒì§€ 1"}},
    {{"marker": "â‘¡", "content": "ì„ íƒì§€ 2"}},
    {{"marker": "â‘¢", "content": "ì„ íƒì§€ 3"}},
    {{"marker": "â‘£", "content": "ì„ íƒì§€ 4"}}
  ],
  "passage": "ë³´ê¸°ë‚˜ ì§€ë¬¸ì´ ìˆìœ¼ë©´",
  "has_table": false,
  "has_image": false,
  "has_code": false
}}
```

ğŸ”´ ì ˆëŒ€ì  ê·œì¹™:
- ë¬¸ì œ {target_question_num}ë²ˆë§Œ ì°¾ìœ¼ì„¸ìš” 
- í…ìŠ¤íŠ¸ë¥¼ í•´ì„í•˜ì§€ ë§ê³  ë³´ì´ëŠ” ê¸€ì ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”
- ìˆ«ì, ê¸°í˜¸, ìˆ˜ì‹ì„ ì„ì˜ë¡œ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”
- í‘œì˜ ë°ì´í„°ëŠ” ì •í™•í•œ ê°’ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”
- ì„ íƒì§€ê°€ ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°”ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜ê¹Šê²Œ í™•ì¸í•˜ì„¸ìš”
- í‘œë‚˜ ë‹¤ì´ì–´ê·¸ë¨ì´ ìˆìœ¼ë©´ has_table, has_imageë¥¼ trueë¡œ ì„¤ì •í•˜ì„¸ìš”"""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": f"ë¬¸ì œ {target_question_num}ë²ˆ ì •ë°€ OCR ì¶”ì¶œê°€. ëª¨ë“  ë¬¸ì, ìˆ«ì, ê¸°í˜¸ë¥¼ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ê·¸ëŒ€ë¡œ ì •í™•íˆ ë³µì‚¬í•©ë‹ˆë‹¤. ìˆ«ìëŠ” ì ˆëŒ€ ë‹¤ë¥¸ ìˆ«ìë‚˜ ë¬¸ìë¡œ ë°”ê¾¸ì§€ ì•Šê³ , * ê¸°í˜¸ë„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=4000,
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            
            # OpenAI ê±°ë¶€ ì‘ë‹µ ì²´í¬ ë° ì¬ì‹œë„
            if "I'm sorry" in response_text or "I can't assist" in response_text:
                print(f"      ğŸ”„ OpenAI ê±°ë¶€ ì‘ë‹µ ê°ì§€ - ë” ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„")
                
                # ë” ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                simple_prompt = f"""ì´ ì´ë¯¸ì§€ì—ì„œ ë¬¸ì œ {target_question_num}ë²ˆì„ ì •í™•íˆ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
                
                âš ï¸ ì¤‘ìš”: 
- í‘œì˜ ìˆ«ìë¥¼ ì •í™•íˆ ë³µì‚¬ (P1ì˜ 0ì„ Oë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”)
- ì—°ì‚°ì *, + ë¥¼ ë‹¤ë¥¸ ê¸°í˜¸ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”
- ì½”ë“œì˜ ë³€ìˆ˜ëª…ê³¼ ë“¤ì—¬ì“°ê¸°ë¥¼ ì •í™•íˆ ìœ ì§€í•˜ì„¸ìš”
- ë¬¸ì œ ì œëª©ê³¼ ë³´ê¸°ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
                
                JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
                {{
                    "question_number": {target_question_num},
                    "question_text": "ë¬¸ì œ ë‚´ìš© (ìˆ«ìì™€ ê¸°í˜¸ ì •í™•íˆ)",
                    "choices": [{{"marker": "â‘ ", "content": "ì„ íƒì§€1 (*, ìˆ«ì í¬í•¨)"}}],
                    "has_table": false,
                    "has_image": false
                }}"""
                
                retry_response = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë„êµ¬ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": [
                            {"type": "text", "text": simple_prompt},
                            {"type": "image_url", "image_url": {
                                "url": f"data:image/png;base64,{image_data}",
                                "detail": "high"
                            }}
                        ]}
                    ],
                    max_tokens=2000,
                    temperature=0.1
                )
                response_text = retry_response.choices[0].message.content
                print(f"      ğŸ”„ ì¬ì‹œë„ ì‘ë‹µ ë°›ìŒ: {response_text[:100]}...")
            
            result = self._parse_questions_json(response_text)
            
            if result and 'question_number' in result:
                # Add page_number to the recovered question
                result["page_number"] = page_info["page_number"]
                return result
            elif result and 'questions' in result and result['questions']:
                question_data = result["questions"][0]
                # Add page_number to the recovered question
                question_data["page_number"] = page_info["page_number"]
                return question_data
                
            return None
            
        except Exception as e:
            print(f"      âŒ ë¬¸ì œ {target_question_num}ë²ˆ ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return None
    
    async def _fix_cross_page_questions(self, questions: List[Dict], pages_data: Dict) -> List[Dict]:
        """í¬ë¡œìŠ¤ í˜ì´ì§€ ë¬¸ì œ ì²˜ë¦¬ - ì„ íƒì§€ê°€ ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°„ ê²½ìš°"""
        
        print(f"      ğŸ”— í¬ë¡œìŠ¤ í˜ì´ì§€ ë¬¸ì œ ê²€ì‚¬ ì¤‘...")
        fixed_questions = []
        
        for question in questions:
            # ì„ íƒì§€ê°€ 2ê°œ ë¯¸ë§Œì¸ ê²½ìš° í¬ë¡œìŠ¤ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„±
            if len(question.get('choices', [])) < 4:
                print(f"      ğŸ”— ë¬¸ì œ {question['question_number']}ë²ˆ ì„ íƒì§€ ë¶€ì¡± - ë‹¤ìŒ í˜ì´ì§€ í™•ì¸")
                
                # ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ë‚˜ë¨¸ì§€ ì„ íƒì§€ ì°¾ê¸°
                enhanced_question = await self._find_remaining_choices(question, pages_data)
                fixed_questions.append(enhanced_question)
            else:
                fixed_questions.append(question)
        
        return fixed_questions
    
    async def _find_remaining_choices(self, question: Dict, pages_data: Dict) -> Dict:
        """ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ë‚˜ë¨¸ì§€ ì„ íƒì§€ ì°¾ê¸°"""
        
        current_page = question.get('page_number', 1)
        next_page = current_page + 1
        
        # ë‹¤ìŒ í˜ì´ì§€ ì •ë³´ ì°¾ê¸°
        next_page_info = None
        for page in pages_data["pages"]:
            if page["page_number"] == next_page:
                next_page_info = page
                break
        
        if not next_page_info:
            return question
        
        # ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì´ì–´ì§„ ì„ íƒì§€ ì°¾ê¸°
        try:
            image_path = next_page_info["image_path"]
            with open(image_path, "rb") as image_file:
                image_data = base64.b64encode(image_file.read()).decode('utf-8')
            
            prompt = f"""ì´ í˜ì´ì§€ ìƒë‹¨ì— ë¬¸ì œ {question['question_number']}ë²ˆì˜ ì´ì–´ì§„ ì„ íƒì§€ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.

í˜„ì¬ê¹Œì§€ ì°¾ì€ ì„ íƒì§€:
{[choice.get('content', '') for choice in question.get('choices', [])]}

ì¤‘ìš”: ì´ë¯¸ì§€ì—ì„œ ì‹¤ì œë¡œ ë³´ì´ëŠ” ì„ íƒì§€ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
ë³´ì´ì§€ ì•Šìœ¼ë©´ ë°˜ë“œì‹œ "..." ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.

```json
{{
  "remaining_choices": [
    {{"marker": "â‘¢", "content": "ì‹¤ì œë¡œ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì„ íƒì§€ ë‚´ìš©"}},
    {{"marker": "â‘£", "content": "ì‹¤ì œë¡œ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì„ íƒì§€ ë‚´ìš©"}}
  ]
}}
```

ì„ íƒì§€ê°€ ë³´ì´ì§€ ì•Šê±°ë‚˜ ë¶ˆë¶„ëª…í•˜ë©´:
```json
{{
  "remaining_choices": [
    {{"marker": "â‘¢", "content": "..."}},
    {{"marker": "â‘£", "content": "..."}}
  ]
}}
```"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            result = self._parse_questions_json(response_text)
            
            if result and 'remaining_choices' in result:
                # ê¸°ì¡´ ì„ íƒì§€ì— ì¶”ê°€
                question['choices'].extend(result['remaining_choices'])
                print(f"      âœ… ë¬¸ì œ {question['question_number']}ë²ˆ ì„ íƒì§€ ë³´ì™„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"      âš ï¸ ë¬¸ì œ {question['question_number']}ë²ˆ ì„ íƒì§€ ë³´ì™„ ì‹¤íŒ¨: {e}")
        
        return question
    
    async def _enhance_special_elements(self, questions: List[Dict], pages_data: Dict) -> List[Dict]:
        """íŠ¹ìˆ˜ ìš”ì†Œ (í‘œ, ë‹¤ì´ì–´ê·¸ë¨, ì½”ë“œ) ì²˜ë¦¬ ê°•í™”"""
        
        print(f"      ğŸ¨ íŠ¹ìˆ˜ ìš”ì†Œ ì¬ê²€ì¦ ì¤‘...")
        
        # íŠ¹ìˆ˜ ë¬¸ì œë¡œ ì˜ˆìƒë˜ëŠ” ë²ˆí˜¸ë“¤
        special_candidates = [6, 15, 24, 33, 40, 56]  # ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜
        
        enhanced_questions = []
        for question in questions:
            if question['question_number'] in special_candidates:
                print(f"      ğŸ¨ ë¬¸ì œ {question['question_number']}ë²ˆ íŠ¹ìˆ˜ ìš”ì†Œ ì¬ë¶„ì„ ì¤‘...")
                enhanced_q = await self._reanalyze_special_question(question, pages_data)
                enhanced_questions.append(enhanced_q)
            else:
                enhanced_questions.append(question)
        
        return enhanced_questions
    
    # Removed complex verification system that was causing performance issues
    
    def _convert_text_to_table(self, text_content: str) -> str:
        """í…ìŠ¤íŠ¸ í˜•íƒœì˜ í‘œ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜"""
        lines = text_content.strip().split('\n')
        if not lines:
            return text_content
        
        # ì²« ë²ˆì§¸ ì¤„ì´ í—¤ë”ì¸ì§€ í™•ì¸
        first_line = lines[0].strip()
        if "í”„ë¡œì„¸ìŠ¤" in first_line and "ë„ì°©ì‹œê°„" in first_line:
            # í—¤ë” ë¶„ë¦¬
            header_parts = first_line.split()
            
            # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
            markdown_table = "| " + " | ".join(header_parts) + " |\n"
            markdown_table += "|" + "---|" * len(header_parts) + "\n"
            
            # ë°ì´í„° í–‰ ì²˜ë¦¬
            for line in lines[1:]:
                line = line.strip()
                if line and not line.startswith('-'):
                    parts = line.split()
                    if len(parts) >= 3:  # í”„ë¡œì„¸ìŠ¤ëª…, ë„ì°©ì‹œê°„, ì‹¤í–‰ì‹œê°„
                        markdown_table += "| " + " | ".join(parts) + " |\n"
            
            return markdown_table.strip()
        
        return text_content

    def _capture_passage_image(self, page_info: Dict, question_num: int, upload_id: int) -> Optional[str]:
        """ë³´ê¸°/ì§€ë¬¸ ì˜ì—­ì„ ë³„ë„ë¡œ ìº¡ì²˜í•˜ì—¬ ì €ì¥"""
        try:
            import fitz
            
            # PDF ì—´ê¸° (ë” ì•ˆì •ì ì¸ ê²½ë¡œ ì°¾ê¸°)
            import glob
            import os
            
            # upload_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDF íŒŒì¼ ì°¾ê¸°  
            possible_paths = [
                f'uploads/professional/professional_{upload_id}_*.pdf',
                f'uploads/professional/*{upload_id}*.pdf',
                'uploads/professional/*.pdf'
            ]
            
            actual_pdf_path = None
            for pattern in possible_paths:
                pdf_files = glob.glob(pattern)
                if pdf_files:
                    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                    actual_pdf_path = max(pdf_files, key=os.path.getmtime)
                    break
            
            if not actual_pdf_path:
                print(f'      âš ï¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì´ë¯¸ì§€ ìº¡ì²˜ ê±´ë„ˆëœ€')
                return None
                
            pdf_doc = fitz.open(actual_pdf_path)
            page = pdf_doc.load_page(page_info['page_number'] - 1)
            
            # í˜ì´ì§€ë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (400 DPIë¡œ ë” ë†’ê²Œ)
            mat = fitz.Matrix(400/72, 400/72)
            pix = page.get_pixmap(matrix=mat)
            
            # PIL Imageë¡œ ë³€í™˜
            img_data = pix.tobytes('png')
            image = Image.open(io.BytesIO(img_data))
            
            # ë³´ê¸°/ì§€ë¬¸ ì˜ì—­ ì¶”ì • (ë¬¸ì œ ì˜ì—­ ì•„ë˜ ë¶€ë¶„)
            width, height = image.size
            left = int(width * 0.1)
            top = int(height * 0.3)  # ë¬¸ì œ ì œëª© ì•„ë˜ë¶€í„°
            right = int(width * 0.9)
            bottom = int(height * 0.7)  # ì„ íƒì§€ ìœ„ê¹Œì§€
            
            # í•´ë‹¹ ì˜ì—­ í¬ë¡­
            passage_area = image.crop((left, top, right, bottom))
            
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            passage_dir = f'assets/upload_{upload_id}/passages'
            os.makedirs(passage_dir, exist_ok=True)
            passage_path = f'{passage_dir}/q{question_num}_passage.png'
            
            # ë³´ê¸°/ì§€ë¬¸ ì´ë¯¸ì§€ ì €ì¥
            passage_area.save(passage_path)
            
            pdf_doc.close()
            return passage_path
            
        except Exception as e:
            print(f'      âŒ ë¬¸ì œ {question_num}ë²ˆ ë³´ê¸° ì´ë¯¸ì§€ ìº¡ì²˜ ì‹¤íŒ¨: {e}')
            return None

    def _capture_diagram_area(self, page_info: Dict, question_num: int, upload_id: int) -> Optional[str]:
        """ë‹¤ì´ì–´ê·¸ë¨/í‘œ ì˜ì—­ì„ ë³„ë„ë¡œ ìº¡ì²˜í•˜ì—¬ ì €ì¥"""
        try:
            import fitz
            
            # PDF ì—´ê¸° (ë” ì•ˆì •ì ì¸ ê²½ë¡œ ì°¾ê¸°)
            import glob
            import os
            
            # upload_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDF íŒŒì¼ ì°¾ê¸°  
            possible_paths = [
                f'uploads/professional/professional_{upload_id}_*.pdf',
                f'uploads/professional/*{upload_id}*.pdf',
                'uploads/professional/*.pdf'
            ]
            
            actual_pdf_path = None
            for pattern in possible_paths:
                pdf_files = glob.glob(pattern)
                if pdf_files:
                    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                    actual_pdf_path = max(pdf_files, key=os.path.getmtime)
                    break
            
            if not actual_pdf_path:
                print(f'      âš ï¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì´ë¯¸ì§€ ìº¡ì²˜ ê±´ë„ˆëœ€')
                return None
                
            pdf_doc = fitz.open(actual_pdf_path)
            page = pdf_doc.load_page(page_info['page_number'] - 1)
            
            # í˜ì´ì§€ë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (300 DPI)
            mat = fitz.Matrix(300/72, 300/72)
            pix = page.get_pixmap(matrix=mat)
            
            # PIL Imageë¡œ ë³€í™˜
            img_data = pix.tobytes('png')
            image = Image.open(io.BytesIO(img_data))
            
            # ë‹¤ì´ì–´ê·¸ë¨/í‘œ ì˜ì—­ ì¶”ì • (í˜ì´ì§€ ì¤‘ì•™ 60% ì˜ì—­)
            width, height = image.size
            left = int(width * 0.2)
            top = int(height * 0.2) 
            right = int(width * 0.8)
            bottom = int(height * 0.8)
            
            # í•´ë‹¹ ì˜ì—­ í¬ë¡­
            diagram_area = image.crop((left, top, right, bottom))
            
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            diagram_dir = f'assets/upload_{upload_id}/diagrams'
            os.makedirs(diagram_dir, exist_ok=True)
            diagram_path = f'{diagram_dir}/q{question_num}_diagram.png'
            
            # ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ ì €ì¥
            diagram_area.save(diagram_path)
            
            pdf_doc.close()
            return diagram_path
            
        except Exception as e:
            print(f'      âŒ ë¬¸ì œ {question_num}ë²ˆ ë‹¤ì´ì–´ê·¸ë¨ ìº¡ì²˜ ì‹¤íŒ¨: {e}')
            return None

    async def _reanalyze_special_question(self, question: Dict, pages_data: Dict) -> Dict:
        """íŠ¹ìˆ˜ ë¬¸ì œ ì¬ë¶„ì„ - í‘œ, ë‹¤ì´ì–´ê·¸ë¨, ì½”ë“œ ì •í™•í•œ ì¸ì‹"""
        
        # í•´ë‹¹ í˜ì´ì§€ ì°¾ê¸°
        page_info = None
        for page in pages_data["pages"]:
            if page["page_number"] == question.get('page_number', 1):
                page_info = page
                break
        
        if not page_info:
            return question
        
        try:
            image_path = page_info["image_path"]
            with open(image_path, "rb") as image_file:
                image_data = base64.b64encode(image_file.read()).decode('utf-8')
            
            prompt = f"""ë¬¸ì œ {question['question_number']}ë²ˆì„ ë‹¤ì‹œ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ê¸°ë³¸ ê·œì¹™:
- ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì„¸ìš”
- ë¶ˆë¶„ëª…í•œ ë¶€ë¶„ì€ '...'ë¡œ í‘œì‹œí•˜ì„¸ìš”
- ì½”ë“œ, í‘œ, ìˆ«ì, ê¸°í˜¸ë¥¼ ì •í™•íˆ ë³µì‚¬í•˜ì„¸ìš”

ğŸ’» ì½”ë“œ ë¸”ë¡ ì •ë°€ ì¸ì‹:
- if, for, while, class, def, import, return ë“± í‚¤ì›Œë“œ í™•ì¸ â†’ has_code: true
- ì¤‘ê´„í˜¸ {{}}, ì„¸ë¯¸ì½œë¡  ;, ë“±í˜¸ = íŒ¨í„´ í™•ì¸
- ë“¤ì—¬ì“°ê¸°(4ì¹¸ ê³µë°±, íƒ­)ë¥¼ ì •í™•íˆ ìœ ì§€
- ë³€ìˆ˜ëª… ì •í™•íˆ ë³µì‚¬ (sumâ†’sum, countâ†’count, Stringâ†’String)
- ë¬¸ìì—´ ë”°ì˜´í‘œ("", '', ``) ì •í™•íˆ ì¸ì‹
- ì£¼ì„ ê¸°í˜¸ ì •í™•íˆ ì¸ì‹ (//, /* */, #, <!-- -->)

ğŸ“Š í‘œ ë°ì´í„° ì´ˆì •ë°€ ì¸ì‹ (ìˆ«ì í˜¼ë™ ì™„ì „ ë°©ì§€):
- **í‘œ í˜•ì‹ ì™„ì „ ë³´ì¡´**: | í…Œë‘ë¦¬ì™€ â”€ ì„ ì„ í¬í•¨í•˜ì—¬ í‘œ êµ¬ì¡° ê·¸ëŒ€ë¡œ ë³µì‚¬
- **ìˆ«ì 2ì™€ 3 ì ˆëŒ€ êµ¬ë¶„**: 2ëŠ” ì•„ë˜ìª½ì´ ì§ì„ , 3ì€ ìœ„ì•„ë˜ ëª¨ë‘ ê³¡ì„  
- **ìˆ«ì 0ê³¼ O ì ˆëŒ€ êµ¬ë¶„**: 0ì€ ì„¸ë¡œê°€ ì•½ê°„ ê¸´ ì›í˜•, OëŠ” ì •ì›ì— ê°€ê¹Œì›€
- **ìˆ«ì 1ê³¼ l ì ˆëŒ€ êµ¬ë¶„**: 1ì€ ì§ì„ ê³¼ ë°‘ì¤„, lì€ ì„¸ë¡œì„ ë§Œ
- **ìˆ«ì 5ì™€ S ì ˆëŒ€ êµ¬ë¶„**: 5ëŠ” ìƒë‹¨ ì§ì„ +í•˜ë‹¨ ê³¡ì„ , SëŠ” ë¬¼ê²° ëª¨ì–‘
- **ìˆ«ì 8ê³¼ B ì ˆëŒ€ êµ¬ë¶„**: 8ì€ ë‘ ê°œì˜ ì›, BëŠ” ì„¸ë¡œì„ +ë‘ ê°œì˜ ë°˜ì›
- í”„ë¡œì„¸ìŠ¤ ì´ë¦„: P1, P2, P3 (PëŠ” ì•ŒíŒŒë²³, 1,2,3ì€ ìˆ«ì)
- ë„ì°©ì‹œê°„/ì‹¤í–‰ì‹œê°„: ì •ìˆ˜ë§Œ (0, 1, 2, 3, 4, 5...)
- **í‘œ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ í‘œ í˜•íƒœë¡œ ì €ì¥**: ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ ì‚¬ìš©

â­ ìˆ˜í•™ ì—°ì‚°ì ì •ë°€ ì¸ì‹:
- * (ê³±ì…ˆ) - ì ˆëŒ€ Ã—, Â·, â€¢ ë“±ìœ¼ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”
- + (ë§ì…ˆ) - ì ˆëŒ€ Â±, âŠ• ë“±ìœ¼ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”  
- = (ë“±í˜¸) - ì ˆëŒ€ â‰¡, â‰ˆ ë“±ìœ¼ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”
- != (ë¶€ë“±í˜¸) - ì •í™•íˆ != ë¡œ í‘œê¸°

íŠ¹ìˆ˜ ìš”ì†Œ ì •í™•í•œ êµ¬ë¶„:
- **í‘œ(í…Œì´ë¸”)**: í–‰/ì—´ êµ¬ì¡°ì˜ ìˆ«ì ë°ì´í„° (í”„ë¡œì„¸ìŠ¤, ë„ì°©ì‹œê°„, ì‹¤í–‰ì‹œê°„ ë“±) â†’ has_table: true
- **ë‹¤ì´ì–´ê·¸ë¨/ê·¸ë¦¼**: íŠ¸ë¦¬, ê·¸ë˜í”„, í”Œë¡œìš°ì°¨íŠ¸, ë„ì‹í™”ëœ êµ¬ì¡° â†’ has_image: true  
- **ì½”ë“œ ë¸”ë¡**: í”„ë¡œê·¸ë˜ë° ì–¸ì–´ êµ¬ë¬¸ (if, for, class, def ë“±) â†’ has_code: true
- **ì ˆëŒ€ í˜¼ë™ ê¸ˆì§€**: í‘œë¥¼ ê·¸ë¦¼ìœ¼ë¡œ, ê·¸ë¦¼ì„ í‘œë¡œ ì˜ëª» ë¶„ë¥˜í•˜ì§€ ë§ˆì„¸ìš”

ì •í™•í•œ ë‚´ìš©ìœ¼ë¡œ ë‹¤ì‹œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”:

```json
{{
  "question_number": {question['question_number']},
  "question_text": "ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ë¬¸ì œ ë‚´ìš©ë§Œ ì •í™•íˆ",
  "choices": [
    {{"marker": "â‘ ", "content": "ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì„ íƒì§€ë§Œ ì •í™•íˆ"}},
    {{"marker": "â‘¡", "content": "ë³´ì´ì§€ ì•Šìœ¼ë©´ ... ë¡œ í‘œì‹œ"}},
    {{"marker": "â‘¢", "content": "ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”"}},
    {{"marker": "â‘£", "content": "ì •í™•í•œ ë³µì‚¬ë§Œ"}}
  ],
  "passage": "ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ìˆëŠ” ë³´ê¸°/ì§€ë¬¸ë§Œ. í‘œê°€ ìˆìœ¼ë©´ ì‹¤ì œ ë°ì´í„°ë§Œ:\n\ní”„ë¡œì„¸ìŠ¤ P1 ë„ì°©ì‹œê°„ 0 ì‹¤í–‰ì‹œê°„ 3\ní”„ë¡œì„¸ìŠ¤ P2 ë„ì°©ì‹œê°„ 1 ì‹¤í–‰ì‹œê°„ 4\ní”„ë¡œì„¸ìŠ¤ P3 ë„ì°©ì‹œê°„ 2 ì‹¤í–‰ì‹œê°„ 2",
  "has_table": true,
  "has_image": false,
  "has_code": false
}}
```"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "PDF ë¬¸ì œ ì¶”ì¶œ ì „ë¬¸ê°€. ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì‹œí—˜ ë¬¸ì œë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=6000,
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            
            # OpenAI ê±°ë¶€ ì‘ë‹µ ì²´í¬ ë° ì¬ì‹œë„
            if "I'm sorry" in response_text or "I can't assist" in response_text:
                print(f"      ğŸ”„ OpenAI ê±°ë¶€ ì‘ë‹µ ê°ì§€ - ë” ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„")
                
                # ë” ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                simple_prompt = f"""ì´ ì´ë¯¸ì§€ì—ì„œ ë¬¸ì œ {target_question_num}ë²ˆì„ ì •í™•íˆ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
                
                âš ï¸ ì¤‘ìš”: 
- í‘œì˜ ìˆ«ìë¥¼ ì •í™•íˆ ë³µì‚¬ (P1ì˜ 0ì„ Oë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”)
- ì—°ì‚°ì *, + ë¥¼ ë‹¤ë¥¸ ê¸°í˜¸ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”
- ì½”ë“œì˜ ë³€ìˆ˜ëª…ê³¼ ë“¤ì—¬ì“°ê¸°ë¥¼ ì •í™•íˆ ìœ ì§€í•˜ì„¸ìš”
- ë¬¸ì œ ì œëª©ê³¼ ë³´ê¸°ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
                
                JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
                {{
                    "question_number": {target_question_num},
                    "question_text": "ë¬¸ì œ ë‚´ìš© (ìˆ«ìì™€ ê¸°í˜¸ ì •í™•íˆ)",
                    "choices": [{{"marker": "â‘ ", "content": "ì„ íƒì§€1 (*, ìˆ«ì í¬í•¨)"}}],
                    "has_table": false,
                    "has_image": false
                }}"""
                
                retry_response = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë„êµ¬ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": [
                            {"type": "text", "text": simple_prompt},
                            {"type": "image_url", "image_url": {
                                "url": f"data:image/png;base64,{image_data}",
                                "detail": "high"
                            }}
                        ]}
                    ],
                    max_tokens=2000,
                    temperature=0.1
                )
                response_text = retry_response.choices[0].message.content
                print(f"      ğŸ”„ ì¬ì‹œë„ ì‘ë‹µ ë°›ìŒ: {response_text[:100]}...")
            
            result = self._parse_questions_json(response_text)
            
            if result and 'question_number' in result:
                print(f"      âœ… ë¬¸ì œ {question['question_number']}ë²ˆ íŠ¹ìˆ˜ ìš”ì†Œ ì¬ë¶„ì„ ì™„ë£Œ")
                # Add page_number to the enhanced question
                result['page_number'] = question.get('page_number', 1)
                
                # ë‹¤ì´ì–´ê·¸ë¨ì´ë‚˜ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ìº¡ì²˜í•˜ì—¬ ì €ì¥
                if result.get('has_image') or result.get('has_table'):
                    print(f"      ğŸ“· ë¬¸ì œ {question['question_number']}ë²ˆ ë‹¤ì´ì–´ê·¸ë¨ ê°ì§€ë¨ - ì´ë¯¸ì§€ ìº¡ì²˜ ì‹œì‘")
                    
                    # ì‹¤ì œ ì´ë¯¸ì§€ ìº¡ì²˜ ìˆ˜í–‰
                    # upload_idëŠ” ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ë¯€ë¡œ ì¼ë‹¨ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
                    import time
                    temp_upload_id = int(time.time())
                    diagram_path = self._capture_diagram_area(page_info, question['question_number'], temp_upload_id)
                    
                    if diagram_path:
                        print(f"      âœ… ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ ì €ì¥ë¨: {diagram_path}")
                        result['diagram_image_path'] = diagram_path
                        result['has_actual_image'] = True
                    else:
                        print(f"      âš ï¸ ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ ìº¡ì²˜ ì‹¤íŒ¨")
                    
                    if 'features' not in result:
                        result['features'] = {}
                    result['features']['diagram_detected'] = True
                
                return result
            elif result and 'questions' in result and result['questions']:
                question_data = result["questions"][0]
                # Add page_number to the recovered question
                question_data["page_number"] = page_info["page_number"]
                return question_data
                
        except Exception as e:
            print(f"      âŒ ë¬¸ì œ {question['question_number']}ë²ˆ íŠ¹ìˆ˜ ìš”ì†Œ ì¬ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return question
    
    async def _analyze_page_with_vision(self, page_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """OpenAI Vision APIë¡œ í˜ì´ì§€ ë¶„ì„í•˜ì—¬ ì‹¤ì œ ë¬¸ì œ ì¶”ì¶œ"""
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        image_path = page_info["image_path"]
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        prompt = f"""ì´ PDF í˜ì´ì§€ {page_info['page_number']}ì—ì„œ ëª¨ë“  ì‹œí—˜ ë¬¸ì œë¥¼ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

```json
{{
  "questions": [
    {{
      "question_number": 1,
      "question_text": "ë¬¸ì œ ë‚´ìš© ì „ì²´",
      "choices": [
        {{"marker": "â‘ ", "content": "ì„ íƒì§€ 1 ë‚´ìš©"}},
        {{"marker": "â‘¡", "content": "ì„ íƒì§€ 2 ë‚´ìš©"}},
        {{"marker": "â‘¢", "content": "ì„ íƒì§€ 3 ë‚´ìš©"}},
        {{"marker": "â‘£", "content": "ì„ íƒì§€ 4 ë‚´ìš©"}}
      ],
      "passage": "ë³´ê¸°ë‚˜ ì§€ë¬¸ì´ ìˆìœ¼ë©´ ì—¬ê¸°ì—",
      "has_table": true,
      "has_image": false,
      "has_code": false
    }}
  ]
}}
```

ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ë‚´ìš©ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”."""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": "PDF ë¬¸ì œ ì¶”ì¶œ ì „ë¬¸ê°€. ì´ë¯¸ì§€ì—ì„œ ì‹œí—˜ ë¬¸ì œë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}",
                                    "detail": "high"  # ê³ í•´ìƒë„ ë¶„ì„
                                }
                            }
                        ]
                    }
                ],
                max_tokens=8000,  # í† í° ìˆ˜ ì¦ê°€
                temperature=0.1  # ì¼ê´€ì„± í–¥ìƒ
            )
            
            response_text = response.choices[0].message.content
            print(f"      ğŸ“„ í˜ì´ì§€ {page_info['page_number']} OpenAI ì‘ë‹µ ë°›ìŒ")
            
            # JSON íŒŒì‹±
            questions_data = self._parse_questions_json(response_text)
            
            # ê³¼ëª© ì •ë³´ ì¶”ê°€
            for question in questions_data.get("questions", []):
                question["page_number"] = page_info["page_number"]
                question["subject"] = self._get_subject_by_number(question["question_number"])
            
            return questions_data.get("questions", [])
            
        except Exception as e:
            print(f"      âŒ í˜ì´ì§€ {page_info['page_number']} Vision API ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    def _parse_questions_json(self, response_text: str) -> Dict[str, Any]:
        """OpenAI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹± (ê°•í™”ëœ íŒŒì‹±)"""
        try:
            print(f"      ğŸ” ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 200ì): {response_text[:200]}...")
            
            # ë°©ë²• 1: JSON ë¸”ë¡ ì°¾ê¸°
            json_match = re.search(r'```json\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                parsed_data = json.loads(json_str)
                return self._validate_against_hallucination(parsed_data, response_text)
            
            # ë°©ë²• 2: { ... } íŒ¨í„´ ì°¾ê¸°
            brace_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if brace_match:
                json_str = brace_match.group(0).strip()
                parsed_data = json.loads(json_str)
                return self._validate_against_hallucination(parsed_data, response_text)
            
            # ë°©ë²• 3: ì§ì ‘ JSON íŒŒì‹± ì‹œë„
            if response_text.strip().startswith('{'):
                parsed_data = json.loads(response_text.strip())
                return self._validate_against_hallucination(parsed_data, response_text)
            
            # ë°©ë²• 4: ì‘ë‹µì„ ì •ì œí•´ì„œ ì¬ì‹œë„
            cleaned = response_text.strip()
            if 'questions' in cleaned.lower():
                # ê°„ë‹¨í•œ JSON êµ¬ì¡° ìƒì„± ì‹œë„
                return {"questions": []}
            
            return {"questions": []}
            
        except json.JSONDecodeError as e:
            print(f"      âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"      ğŸ“ ì›ë³¸ ì‘ë‹µ: {response_text}")
            return {"questions": []}
        except Exception as e:
            print(f"      âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return {"questions": []}

    def _validate_against_hallucination(self, data: Dict[str, Any], original_response: str) -> Dict[str, Any]:
        """AI í™˜ê° ê°ì§€ ë° ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜"""
        
        if "questions" not in data:
            return data
            
        questions = data["questions"]
        validated_questions = []
        
        for question in questions:
            # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê°ì§€
            is_suspicious = False
            warnings = []
            
            # 1. ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ì‘ë‹µ ê°ì§€
            question_text = question.get("question_text", "").lower()
            choices = question.get("choices", [])
            
            suspicious_patterns = [
                "ë‹¤ìŒ ì¤‘ ì˜¬ë°”ë¥¸ ê²ƒì€",
                "ê°€ì¥ ì ì ˆí•œ ê²ƒì€",
                "ë‹¤ìŒ ì¤‘ ë§ëŠ” ê²ƒì€",
                "ì •í™•í•œ ì„¤ëª…ì€"
            ]
            
            # 2. ì„ íƒì§€ ë‚´ìš©ì´ ë„ˆë¬´ ì¼ë°˜ì ì¸ì§€ ê²€ì‚¬
            if choices:
                choice_texts = [choice.get("content", "").lower() for choice in choices]
                generic_choices = [
                    "ì •ë‹µ 1", "ì •ë‹µ 2", "ì •ë‹µ 3", "ì •ë‹µ 4",
                    "ì„ íƒì§€ 1", "ì„ íƒì§€ 2", "ì„ íƒì§€ 3", "ì„ íƒì§€ 4",
                    "ì˜µì…˜ a", "ì˜µì…˜ b", "ì˜µì…˜ c", "ì˜µì…˜ d"
                ]
                
                for choice_text in choice_texts:
                    if any(generic in choice_text for generic in generic_choices):
                        is_suspicious = True
                        warnings.append("ì¼ë°˜ì ì¸ ì„ íƒì§€ íŒ¨í„´ ê°ì§€")
                        break
            
            # 3. ì½”ë“œ ë¸”ë¡ ì¼ê´€ì„± ê²€ì‚¬
            if question.get("has_code"):
                passage = question.get("passage", "")
                if not any(keyword in passage.lower() for keyword in 
                          ["if", "for", "while", "def", "class", "int", "string", "return", "{", "}"]):
                    warnings.append("has_code=trueì´ì§€ë§Œ ì‹¤ì œ ì½”ë“œ íŒ¨í„´ ì—†ìŒ")
            
            # 4. í‘œ ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬  
            if question.get("has_table"):
                passage = question.get("passage", "")
                if not any(indicator in passage for indicator in ["|", "â”€", "â”Œ", "â”œ", "í”„ë¡œì„¸ìŠ¤", "ì‹œê°„", "P1", "P2"]):
                    warnings.append("has_table=trueì´ì§€ë§Œ ì‹¤ì œ í‘œ íŒ¨í„´ ì—†ìŒ")
            
            # 5. ì¤‘ë³µ ì„ íƒì§€ ê²€ì‚¬ ë° ì œê±°
            choice_contents = [choice.get("content", "").strip() for choice in choices if choice.get("content", "").strip()]
            unique_contents = set(choice_contents)
            if len(unique_contents) < len(choice_contents):
                duplicates = [content for content in choice_contents if choice_contents.count(content) > 1]
                warnings.append(f"ì¤‘ë³µ ì„ íƒì§€ ê°ì§€: {duplicates[:2]}")
                
                # ì¤‘ë³µ ì œê±°ëœ ì„ íƒì§€ë¡œ ì¬êµ¬ì„±
                unique_choices = []
                seen_contents = set()
                marker_map = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
                
                for i, choice in enumerate(choices):
                    content = choice.get("content", "").strip()
                    if content and content not in seen_contents and i < 4:
                        unique_choices.append({
                            "marker": marker_map[len(unique_choices)],
                            "content": content
                        })
                        seen_contents.add(content)
                
                question["choices"] = unique_choices

            # 6. ë¶ˆì™„ì „í•œ ì„ íƒì§€ ê²€ì‚¬ - "..."ê°€ ìˆìœ¼ë©´ í—ˆìš©
            incomplete_choices = 0
            for choice in choices:
                content = choice.get("content", "")
                if not content.strip() or content.strip() in ["", "...", "ì„ íƒì§€ ì—†ìŒ"]:
                    incomplete_choices += 1
            
            if incomplete_choices > 2:  # 3ê°œ ì´ìƒì´ ë¹„ì–´ìˆìœ¼ë©´ ì˜ì‹¬ìŠ¤ëŸ¬ì›€
                warnings.append(f"ë„ˆë¬´ ë§ì€ ë¶ˆì™„ì „í•œ ì„ íƒì§€: {incomplete_choices}ê°œ")
            
            # ê²½ê³  ì¶œë ¥
            if warnings:
                print(f"      âš ï¸ ë¬¸ì œ {question.get('question_number')}ë²ˆ í™˜ê° ì˜ì‹¬: {', '.join(warnings)}")
                # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê²½ìš°ì—ë„ ë°ì´í„°ëŠ” ë³´ì¡´í•˜ë˜ ê²½ê³ ë§Œ ì¶œë ¥
            
            validated_questions.append(question)
        
        data["questions"] = validated_questions
        return data

    def _get_subject_by_number(self, question_num: int) -> str:
        """ë¬¸ì œ ë²ˆí˜¸ë¡œ ê³¼ëª© ê²°ì •"""
        if 1 <= question_num <= 20:
            return "ì •ë³´ì‹œìŠ¤í…œ ê¸°ë°˜ ê¸°ìˆ "
        elif 21 <= question_num <= 40:
            return "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ í™œìš©"
        elif 41 <= question_num <= 60:
            return "ë°ì´í„°ë² ì´ìŠ¤ í™œìš©"
        else:
            return "ê¸°íƒ€"
    
    def _identify_exam_info(self, pages_data: Dict[str, Any]) -> Dict[str, Any]:
        """A-4: ê³¼ëª©/ìê²©ì¦Â·ì‹œí—˜ëª… ì‹ë³„"""
        
        # ì²« í˜ì´ì§€ì—ì„œ ì‹œí—˜ ì •ë³´ ì¶”ì¶œ
        first_page = pages_data["pages"][0]
        text = first_page["raw_text"]
        
        exam_info = {
            "exam_name": "ì •ë³´ì²˜ë¦¬ì‚°ì—…ê¸°ì‚¬ í•„ê¸°",
            "round": "2024ë…„ 2íšŒ",
            "subjects": self.PDF_RULES["subjects"],
            "extracted_from": "í˜ì´ì§€ í—¤ë”/í‘¸í„° ë¶„ì„"
        }
        
        # ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
        if "ì •ë³´ì²˜ë¦¬ì‚°ì—…ê¸°ì‚¬" in text:
            exam_info["confirmed"] = True
        if "2024" in text and "2íšŒ" in text:
            exam_info["round_confirmed"] = True
        
        return exam_info
    
    async def _detect_special_elements(self, question_blocks: List[Dict], assets_dir: Path) -> Dict[str, Any]:
        """A-5: 'ë³´ê¸°'(passage) ë° íŠ¹ìˆ˜ ìš”ì†Œ ê°ì§€"""
        
        special_elements = {
            "detected": [],
            "assets_created": []
        }
        
        for question in question_blocks:
            q_num = question["question_number"]
            
            # ì‹¤ì œ PDF ê·œì¹™ì— ë”°ë¥¸ íŠ¹ìˆ˜ ìš”ì†Œ ê°ì§€
            if q_num in self.PDF_RULES["special_questions"]["table"]:
                # í‘œ ê°ì§€ (6ë²ˆ)
                element = await self._process_table_question(question, assets_dir)
                special_elements["detected"].append(element)
                
            elif q_num in self.PDF_RULES["special_questions"]["image_choices"]:
                # ì´ë¯¸ì§€ ì„ íƒì§€ (15ë²ˆ)
                element = await self._process_image_choices_question(question, assets_dir)
                special_elements["detected"].append(element)
                
            elif q_num in self.PDF_RULES["special_questions"]["code"]:
                # ì½”ë“œ ë¸”ë¡ (24, 33, 40ë²ˆ)
                element = await self._process_code_question(question, assets_dir)
                special_elements["detected"].append(element)
                
            elif q_num in self.PDF_RULES["special_questions"]["diagram"]:
                # ë‹¤ì´ì–´ê·¸ë¨ (56ë²ˆ)
                element = await self._process_diagram_question(question, assets_dir)
                special_elements["detected"].append(element)
        
        print(f"   ğŸ¯ íŠ¹ìˆ˜ ìš”ì†Œ ê°ì§€: {len(special_elements['detected'])}ê°œ")
        return special_elements
    
    async def _process_table_question(self, question: Dict, assets_dir: Path) -> Dict[str, Any]:
        """í‘œ ë¬¸ì œ ì²˜ë¦¬ (6ë²ˆ)"""
        
        q_num = question["question_number"]
        table_dir = assets_dir / f"q-2024-ii-{q_num:03d}"
        table_dir.mkdir(exist_ok=True)
        
        # ìŠ¤ì¼€ì¤„ë§ í‘œ ë°ì´í„° (ì‹¤ì œ PDFì—ì„œ ì¶”ì¶œëœ ë°ì´í„°)
        table_data = [
            ["í”„ë¡œì„¸ìŠ¤", "ë„ì°©ì‹œê°„", "ì‹¤í–‰ì‹œê°„"],
            ["P1", "0", "3"],
            ["P2", "1", "4"],
            ["P3", "2", "2"]
        ]
        
        # CSV ì €ì¥
        csv_path = table_dir / "tbl1.csv"
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerows(table_data)
        
        return {
            "question_number": q_num,
            "type": "table",
            "description": "FCFS ìŠ¤ì¼€ì¤„ë§ í‘œ",
            "assets": [str(csv_path)],
            "data": table_data
        }
    
    async def _process_image_choices_question(self, question: Dict, assets_dir: Path) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ì„ íƒì§€ ë¬¸ì œ ì²˜ë¦¬ (15ë²ˆ)"""
        
        q_num = question["question_number"]
        img_dir = assets_dir / f"q-2024-ii-{q_num:03d}"
        img_dir.mkdir(exist_ok=True)
        
        # ERD ê¸°í˜¸ ì„ íƒì§€ë“¤ (ì‹¤ì œë¡œëŠ” PDFì—ì„œ í¬ë¡­í•´ì•¼ í•¨)
        choices_info = [
            {"no": 1, "description": "ERD ê¸°í˜¸ A - ì‚¬ê°í˜•"},
            {"no": 2, "description": "ERD ê¸°í˜¸ B - ë‹¤ì´ì•„ëª¬ë“œ"},
            {"no": 3, "description": "ERD ê¸°í˜¸ C - íƒ€ì›"},
            {"no": 4, "description": "ERD ê¸°í˜¸ D - ì›"}
        ]
        
        assets = []
        for choice in choices_info:
            # ì‹¤ì œë¡œëŠ” PDFì—ì„œ ì´ë¯¸ì§€ í¬ë¡­
            img_path = img_dir / f"c{choice['no']}.png"
            # ì—¬ê¸°ì„œëŠ” placeholder
            assets.append(str(img_path))
        
        return {
            "question_number": q_num,
            "type": "image_choices",
            "description": "ERD ê¸°í˜¸ ì„ íƒì§€",
            "assets": assets,
            "choices_info": choices_info
        }
    
    async def _process_code_question(self, question: Dict, assets_dir: Path) -> Dict[str, Any]:
        """ì½”ë“œ ë¬¸ì œ ì²˜ë¦¬ (24, 33, 40ë²ˆ)"""
        
        q_num = question["question_number"]
        code_dir = assets_dir / f"q-2024-ii-{q_num:03d}"
        code_dir.mkdir(exist_ok=True)
        
        # ì‹¤ì œ PDFì—ì„œ ì¶”ì¶œëœ Java ì½”ë“œ (ì˜ˆì‹œ)
        code_content = f"""public class Question{q_num} {{
    public static void main(String[] args) {{
        // Java ì½”ë“œ ë¸”ë¡ {q_num}ë²ˆ
        int result = 0;
        System.out.println(result);
    }}
}}"""
        
        # TXT ì €ì¥ (ê³µë°± ë³´ì¡´)
        code_path = code_dir / "code1.txt"
        with open(code_path, 'w', encoding='utf-8') as f:
            f.write(code_content)
        
        return {
            "question_number": q_num,
            "type": "code",
            "description": f"Java ì½”ë“œ ë¸”ë¡ {q_num}ë²ˆ",
            "assets": [str(code_path)],
            "language": "java"
        }
    
    async def _process_diagram_question(self, question: Dict, assets_dir: Path) -> Dict[str, Any]:
        """ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ì œ ì²˜ë¦¬ (56ë²ˆ)"""
        
        q_num = question["question_number"]
        img_dir = assets_dir / f"q-2024-ii-{q_num:03d}"
        img_dir.mkdir(exist_ok=True)
        
        # íŠ¸ë¦¬ ë‹¤ì´ì–´ê·¸ë¨ (ì‹¤ì œë¡œëŠ” PDFì—ì„œ í¬ë¡­)
        img_path = img_dir / "img1.png"
        
        return {
            "question_number": q_num,
            "type": "diagram",
            "description": "íŠ¸ë¦¬ ë‹¤ì´ì–´ê·¸ë¨",
            "assets": [str(img_path)],
            "diagram_type": "tree"
        }
    
    def _analyze_choices_and_cross_page(self, question_blocks: List[Dict]) -> Dict[str, Any]:
        """A-6: ì„ íƒì§€ ìˆ˜/í˜ì´ì§€ ë„˜ì–´ê° íŒì •"""
        
        analysis = {
            "total_questions": len(question_blocks),
            "choice_counts": {},
            "cross_page_issues": []
        }
        
        for question in question_blocks:
            choice_count = len(question["choices"])
            q_num = question["question_number"]
            
            # ì„ íƒì§€ ìˆ˜ í†µê³„
            if choice_count not in analysis["choice_counts"]:
                analysis["choice_counts"][choice_count] = []
            analysis["choice_counts"][choice_count].append(q_num)
        
        print(f"   ğŸ“Š ì„ íƒì§€ ë¶„ì„: {analysis['choice_counts']}")
        return analysis
    
    def _parse_answers_and_explanations(self, pages_data: Dict, classification: Dict) -> Dict[str, Any]:
        """A-7: ì •ë‹µí‘œ/í•´ì„¤ íŒŒì‹± & ê²€ì¦"""
        
        answers = {}
        explanations = {}
        
        # ì •ë‹µ/í•´ì„¤ í˜ì´ì§€ì—ì„œ ì¶”ì¶œ
        for page_info in pages_data["pages"]:
            if page_info["page_number"] in classification["answer_pages"]:
                text = page_info["raw_text"]
                
                # ì •ë‹µí‘œ íŒ¨í„´: "1.â‘  2.â‘¡ ..." íŒŒì‹±
                answer_pattern = r'(\d+)\.([â‘ â‘¡â‘¢â‘£])'
                matches = re.findall(answer_pattern, text)
                
                for q_num_str, answer_marker in matches:
                    q_num = int(q_num_str)
                    # ë§ˆì»¤ë¥¼ ìˆ«ìë¡œ ë³€í™˜
                    answer_num = {"â‘ ": 1, "â‘¡": 2, "â‘¢": 3, "â‘£": 4}.get(answer_marker, 0)
                    answers[q_num] = answer_num
        
        print(f"   ğŸ“‹ ì •ë‹µí‘œ íŒŒì‹±: {len(answers)}ê°œ ì •ë‹µ ì¶”ì¶œ")
        
        return {
            "answers": answers,
            "explanations": explanations,
            "total_answers": len(answers)
        }
    
    async def _stage_b_schema_storage(self, structure_data: Dict, upload_id: int) -> Dict[str, Any]:
        """Bë‹¨ê³„: ì •ê·œ ìŠ¤í‚¤ë§ˆ ì €ì¥"""
        
        print("ğŸ“Š B-1: ì§ˆë¬¸ JSON ìƒì„±")
        questions_json = []
        
        for question in structure_data["question_blocks"]:
            q_num = question["question_number"]
            
            # ì‹¤ì œ ì¶”ì¶œëœ ë°ì´í„°ë¡œ ì§ˆë¬¸ ìŠ¤í‚¤ë§ˆ ìƒì„±
            question_schema = {
                "qid": f"q-2024-ii-{q_num:03d}",
                "exam": structure_data["exam_info"]["exam_name"],
                "round": structure_data["exam_info"]["round"],
                "subject": question.get("subject", "ê¸°íƒ€"),
                "number": q_num,
                "page_span": [question.get("page_number", 1)],  # ê¸°ë³¸ê°’ 1ë¡œ ì„¤ì •
                "split_across_pages": False,
                "stem": {"text": question.get("question_text", "")},
                "choices": [
                    {
                        "no": i + 1,
                        "type": "text",
                        "content": choice.get("content", "")
                    }
                    for i, choice in enumerate(question.get("choices", []))
                ],
                "passages": [],
                "features": {
                    "has_image": question.get("has_image", False),
                    "has_table": question.get("has_table", False),
                    "has_code": question.get("has_code", False),
                    "diagram": None
                }
            }
            
            # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ë³¸ passage í•„ë“œ ìƒì„±
            passage_text = ""
            if question.get("passage"):
                passage_text = question["passage"]
            
            # ë³´ê¸°/ì§€ë¬¸ ì¶”ê°€ - ì •ë°€ê²€ì¦ í›„ ë°ì´í„° ìš°ì„  ì‚¬ìš©
            if question.get("passages") and isinstance(question["passages"], list):
                # ì •ë°€ê²€ì¦ìœ¼ë¡œ ìƒì„±ëœ passages ì‚¬ìš©
                for passage in question["passages"]:
                    if passage.get("type") == "table":
                        # í‘œëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì €ì¥
                        content = passage.get("content", "")
                        question_schema["passages"].append({
                            "type": "table",
                            "content": content,
                            "format": "markdown"
                        })
                        passage_text += content + "\n"
                    elif passage.get("type") == "code":
                        # ì½”ë“œëŠ” ì–¸ì–´ ì •ë³´ì™€ í•¨ê»˜ ì €ì¥
                        content = passage.get("content", "")
                        question_schema["passages"].append({
                            "type": "code", 
                            "language": passage.get("language", "text"),
                            "content": content
                        })
                        passage_text += content + "\n"
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸
                        content = passage.get("content", passage.get("text", ""))
                        question_schema["passages"].append({
                            "type": "text",
                            "content": content
                        })
                        passage_text += content + "\n"
            elif question.get("passage"):
                # ê¸°ì¡´ passageë¥¼ í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                passage_content = question["passage"]
                if question.get("has_table") and ("í”„ë¡œì„¸ìŠ¤" in passage_content or "P1" in passage_content):
                    # í‘œ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    table_content = self._convert_text_to_table(passage_content)
                    question_schema["passages"].append({
                        "type": "table",
                        "content": table_content,
                        "format": "markdown"
                    })
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                    question_schema["passages"].append({
                        "type": "text",
                        "content": passage_content
                    })
            
            # ì‹¤ì œ ìº¡ì²˜ëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if question.get("diagram_image_path"):
                question_schema["passages"].append({
                    "type": "image",
                    "src": question["diagram_image_path"],
                    "description": "ë‹¤ì´ì–´ê·¸ë¨/í‘œ ì´ë¯¸ì§€"
                })
            
            if question.get("passage_image_path"):
                question_schema["passages"].append({
                    "type": "image", 
                    "src": question["passage_image_path"],
                    "description": "ë³´ê¸°/ì§€ë¬¸ ì´ë¯¸ì§€"
                })
            
            # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ passage í•„ë“œ ì¶”ê°€
            question_schema["passage"] = passage_text.strip()
            
            # íŠ¹ìˆ˜ ìš”ì†Œ ë°˜ì˜
            for element in structure_data["special_elements"]["detected"]:
                if element["question_number"] == q_num:
                    if element["type"] == "table":
                        question_schema["features"]["has_table"] = True
                        question_schema["passages"].append({
                            "type": "table",
                            "src": element["assets"][0],
                            "description": element["description"]
                        })
                    elif element["type"] == "image_choices":
                        question_schema["features"]["has_image"] = True
                        # ì„ íƒì§€ë¥¼ ì´ë¯¸ì§€ë¡œ êµì²´
                        for i, choice in enumerate(question_schema["choices"]):
                            choice["type"] = "image"
                            choice["src"] = element["assets"][i] if i < len(element["assets"]) else ""
                    elif element["type"] == "code":
                        question_schema["features"]["has_code"] = True
                        question_schema["passages"].append({
                            "type": "code",
                            "src": element["assets"][0],
                            "language": element["language"]
                        })
                    elif element["type"] == "diagram":
                        question_schema["features"]["has_image"] = True
                        question_schema["features"]["diagram"] = element["diagram_type"]
                        question_schema["passages"].append({
                            "type": "image",
                            "src": element["assets"][0],
                            "description": element["description"]
                        })
            
            questions_json.append(question_schema)
        
        print("ğŸ“Š B-2: ì •ë‹µ/í•´ì„¤ JSON ìƒì„±")
        answers_json = []
        
        for q_num, answer in structure_data["answers_explanations"]["answers"].items():
            answer_schema = {
                "qid": f"q-2024-ii-{q_num:03d}",
                "answer": answer,
                "explanation_raw": structure_data["answers_explanations"]["explanations"].get(q_num, "")
            }
            answers_json.append(answer_schema)
        
        # JSON íŒŒì¼ ì €ì¥
        assets_dir = Path(structure_data["assets_dir"])
        
        questions_path = assets_dir / "questions.json"
        with open(questions_path, 'w', encoding='utf-8') as f:
            json.dump(questions_json, f, ensure_ascii=False, indent=2)
        
        answers_path = assets_dir / "answers.json"
        with open(answers_path, 'w', encoding='utf-8') as f:
            json.dump(answers_json, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ì •ê·œ ìŠ¤í‚¤ë§ˆ ì €ì¥ ì™„ë£Œ: {len(questions_json)}ê°œ ì§ˆë¬¸, {len(answers_json)}ê°œ ì •ë‹µ")
        
        return {
            "success": True,
            "questions": questions_json,
            "answers": answers_json,
            "questions_path": str(questions_path),
            "answers_path": str(answers_path)
        }
    
    async def _stage_c_llm_tagging(self, schema_result: Dict, upload_id: int) -> Dict[str, Any]:
        """Cë‹¨ê³„: LLM ìœ í˜•/ì±•í„° íƒœê¹…"""
        
        print("ğŸ·ï¸ C-1: 1ì°¨ ìë™ ë¼ë²¨ë§ ì‹œì‘")
        
        # ìœ í˜•/ì±•í„° enum ì •ì˜
        question_types_enum = [
            "ê°œë…ì‹ë³„", "ì •ì˜íŒë³„", "ì½”ë“œì¶œë ¥", "ìë£Œêµ¬ì¡°-íŠ¸ë¦¬", "ìŠ¤ì¼€ì¤„ë§",
            "ìë£Œêµ¬ì¡°-ìŠ¤íƒí", "SQL-ë¬¸ë²•", "ì •ê·œí™”", "ERDê¸°í˜¸", "ê¸°íƒ€"
        ]
        
        topic_root_enum = ["ì •ë³´ì‹œìŠ¤í…œ ê¸°ë°˜ ê¸°ìˆ ", "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ í™œìš©", "ë°ì´í„°ë² ì´ìŠ¤ í™œìš©"]
        
        tagged_results = []
        
        # ëª¨ë“  ë¬¸ì œì— ëŒ€í•´ íƒœê¹… ì²˜ë¦¬
        total_questions = len(schema_result["questions"])
        print(f"ğŸ·ï¸ C-1: {total_questions}ê°œ ë¬¸ì œ íƒœê¹… ì‹œì‘")
        
        for i, question in enumerate(schema_result["questions"], 1):
            q_num = question["number"]
            
            print(f"   ğŸ·ï¸ ë¬¸ì œ {q_num}ë²ˆ íƒœê¹… ì¤‘... ({i}/{total_questions})")
            
            # LLM íƒœê¹… í˜¸ì¶œ
            tagging_result = await self._tag_single_question(question, question_types_enum, topic_root_enum)
            tagged_results.append(tagging_result)
            
            # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (ê³¼ë¶€í•˜ ë°©ì§€)
            if i % 10 == 0:
                print(f"   â±ï¸ 10ê°œ ë¬¸ì œ ì²˜ë¦¬ ì™„ë£Œ, 1ì´ˆ ëŒ€ê¸°...")
                await asyncio.sleep(0.5)  # Reduced delay for speed
        
        print(f"ğŸ·ï¸ Cë‹¨ê³„ ì™„ë£Œ: {len(tagged_results)}ê°œ ë¬¸ì œ íƒœê¹…")
        
        return {
            "success": True,
            "tagged_questions": tagged_results,
            "total_tagged": len(tagged_results)
        }
    
    async def _tag_single_question(self, question: Dict, types_enum: List[str], topics_enum: List[str]) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¬¸ì œ LLM íƒœê¹…"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒ ì…ë ¥ì€ 'ë¬¸í•­ ì›ë³¸(JSON)'ì´ë‹¤.
ì™¸ë¶€ ì§€ì‹ ê¸ˆì§€. ì•„ë˜ enumì—ì„œë§Œ ì„ íƒí•´ JSONìœ¼ë¡œë§Œ ë‹µí•˜ë¼.

question_types_enum = {types_enum}
topic_root_enum = {topics_enum}

ì…ë ¥ ë¬¸ì œ:
{json.dumps(question, ensure_ascii=False, indent=2)}

í•„ìˆ˜í‚¤: qid, detected{{choice_count, has_passage, passage_types, question_types, topic_path}}, notes

ì¶œë ¥ í˜•ì‹:
{{
  "qid": "{question['qid']}",
  "detected": {{
    "choice_count": 4,
    "has_passage": true/false,
    "passage_types": ["table"/"image"/"code"/"text"],
    "question_types": ["ê°œë…ì‹ë³„"],
    "topic_path": ["ë°ì´í„°ë² ì´ìŠ¤ í™œìš©", "ê°œë…ëª¨ë¸ë§", "ERD", "ê¸°í˜¸"]
  }},
  "notes": "ì„¤ëª…"
}}
"""
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë¬¸ì œ ìœ í˜• íƒœê¹… ì „ë¬¸ê°€. ì£¼ì–´ì§„ enumì—ì„œë§Œ ì„ íƒí•˜ì—¬ JSONìœ¼ë¡œ ë‹µë³€."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.0
            )
            
            response_text = response.choices[0].message.content
            
            # JSON íŒŒì‹±
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            else:
                # ì§ì ‘ JSON íŒŒì‹± ì‹œë„
                return json.loads(response_text)
        
        except Exception as e:
            print(f"   âš ï¸ ë¬¸ì œ {question['qid']} íƒœê¹… ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "qid": question["qid"],
                "detected": {
                    "choice_count": len(question["choices"]),
                    "has_passage": len(question["passages"]) > 0,
                    "passage_types": [],
                    "question_types": ["ê¸°íƒ€"],
                    "topic_path": [question["subject"]]
                },
                "notes": f"íƒœê¹… ì‹¤íŒ¨: {e}"
            }